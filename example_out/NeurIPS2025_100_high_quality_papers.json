{
    "4OsgYD7em5": {
        "venue": "ICLR 2025",
        "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
        "link": "https://openreview.net/forum?id=4OsgYD7em5",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly in mathematics and programming tasks. \nIt is widely believed that, similar to how traditional RL helps agents to explore and learn new strategies, RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed the capacity of the corresponding base models. \nIn this study, we take a critical look at \\textit{the current state of RLVR} by systematically probing the reasoning capability boundaries of RLVR-trained LLMs across diverse model families, RL algorithms, and math/coding/visual reasoning benchmarks, using pass@\\textit{k} at large \\textit{k} values as the evaluation metric.\nWhile RLVR improves sampling efficiency towards the correct path, we surprisingly find that current training does \\emph{not} elicit fundamentally new reasoning patterns.\nWe observe that while RLVR-trained models outperform their base models at smaller values of $k$ (\\eg, $k$=1), base models achieve higher pass@$k$ score when $k$ is large.\nMoreover, we observe that the reasoning capability boundary of LLMs often narrows as RLVR training progresses.\nFurther coverage and perplexity analysis shows that the reasoning paths generated by RLVR models are already included in the base models' sampling distribution, suggesting that their reasoning abilities originate from and are \\textit{bounded} by the base model. \nFrom this perspective, treating the base model as an upper bound, our quantitative analysis shows that six popular RLVR algorithms perform similarly and remain far from optimal in fully leveraging the potential of the base model.\nIn contrast, we find that distillation can introduce new reasoning patterns from the teacher and genuinely expand the model\u2019s reasoning capabilities.\nTaken together, our findings suggest that current RLVR methods have not fully realized the potential of RL to elicit genuinely novel reasoning abilities in LLMs. This underscores the need for improved RL paradigms\u2014such as continual scaling and multi-turn agent-environment interaction\u2014to unlock this potential.",
        "decision": "Accept (oral)",
        "review scores": [
            6,
            6,
            6,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "QN0E0KX2LM": {
        "venue": "ICLR 2025",
        "title": "Learning Linear Attention in Polynomial Time",
        "link": "https://openreview.net/forum?id=QN0E0KX2LM",
        "abstract": "Previous research has explored the expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the efficient learnability of Transformers from data has remained an open question.  Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention.  We show that learning the optimal multi head linear attention can be recast as finding the optimal kernel predictor in a suitably defined RKHS.  Moving to generalization, we construct an algorithm that, given a dataset, checks in polynomial time whether the set of best fit multi head linear attention networks on this data all perform an identical computation--a powerful notion for out of distribution generalization.  We empirically validate our theoretical findings on several canonical tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformer models.",
        "decision": "Accept (oral)",
        "review scores": [
            6,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "uAeqQePu4c": {
        "venue": "ICLR 2025",
        "title": "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation",
        "link": "https://openreview.net/forum?id=uAeqQePu4c",
        "abstract": "Recent advancements in large language models (LLMs) underscore the need for more comprehensive evaluation methods to accurately assess their reasoning capabilities. Existing benchmarks are often domain-specific and thus cannot fully capture an LLM\u2019s general reasoning potential. To address this limitation, we introduce the **Knowledge Orthogonal Reasoning Gymnasium (KORGym)**, a dynamic evaluation platform inspired by KOR-Bench and Gymnasium. KORGym offers over fifty games in either textual or visual formats and supports interactive, multi-turn assessments with reinforcement learning scenarios. Using KORGym, we conduct extensive experiments on 19 LLMs and 8 VLMs, revealing consistent reasoning patterns within model families and demonstrating the superior performance of closed-source models. Further analysis examines the effects of modality, reasoning strategies, reinforcement learning techniques, and response length on model performance. We expect KORGym to become a valuable resource for advancing LLM reasoning research and developing evaluation methodologies suited to complex, interactive environments.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "te2RsWcyQp": {
        "venue": "ICLR 2025",
        "title": "Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning",
        "link": "https://openreview.net/forum?id=te2RsWcyQp",
        "abstract": "Existing pretrained models for 3D mesh generation often suffer from data biases and produce low-quality results, while global reinforcement learning (RL) methods rely on object-level rewards that struggle to capture local structure details. To address these challenges, we present $\\textbf{Mesh-RFT}$, a novel fine-grained reinforcement fine-tuning framework that employs Masked Direct Preference Optimization (M-DPO) to enable localized refinement via quality-aware face masking. To facilitate efficient quality evaluation, we introduce an objective topology-aware scoring system to evaluate geometric integrity and topological regularity at both object and face levels through two metrics: Boundary Edge Ratio (BER) and Topology Score (TS). By integrating these metrics into a fine-grained RL strategy, Mesh-RFT becomes the first method to optimize mesh quality at the granularity of individual faces, resolving localized errors while preserving global coherence. Experiment results show that our M-DPO approach reduces Hausdorff Distance (HD) by 24.6\\% and improves Topology Score (TS) by 3.8\\% over pre-trained models, while outperforming global DPO methods with a 17.4\\% HD reduction and 4.9\\% TS gain. These results demonstrate Mesh-RFT\u2019s ability to improve geometric integrity and topological regularity, achieving new state-of-the-art performance in production-ready mesh generation.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            6,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "d6UV0UNgn9": {
        "venue": "ICLR 2025",
        "title": "Affine-Invariant Global Non-Asymptotic Convergence Analysis of BFGS under Self-Concordance",
        "link": "https://openreview.net/forum?id=d6UV0UNgn9",
        "abstract": "In this paper, we establish global non-asymptotic convergence guarantees for the BFGS quasi-Newton method without requiring strong convexity or the Lipschitz continuity of the gradient or Hessian. Instead, we consider the setting where the objective function is strictly convex and strongly self-concordant. For an arbitrary initial point and any arbitrary positive-definite initial Hessian approximation, we prove global linear and superlinear convergence guarantees for BFGS when the step size is determined using a line search scheme satisfying the weak Wolfe conditions.  Moreover, all our global guarantees are affine-invariant, with the convergence rates depending solely on the initial error and the strongly self-concordant constant. Our results extend the global non-asymptotic convergence theory of BFGS beyond traditional assumptions and, for the first time, establish affine-invariant convergence guarantees\u2014aligning with the inherent affine invariance of the BFGS method.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "Sf5nxMRiG7": {
        "venue": "ICLR 2025",
        "title": "Corporate Needs You to Find the Difference: Revisiting Submodular and Supermodular Ratio Optimization Problems",
        "link": "https://openreview.net/forum?id=Sf5nxMRiG7",
        "abstract": "We consider the following question: given a submodular or supermodular set function $f:2^V \\to \\mathbb{R}$, how should one minimize or maximize its average value $f(S)/|S|$ over non-empty subsets $S\\subseteq V$? This problem generalizes several well-known objectives including Densest Subgraph (DSG), Densest Supermodular Set (DSS), and Submodular Function Minimization (SFM). Motivated by recent applications [39, 31], we formalize two new broad problems: the Unrestricted Sparsest Submodular Set (USSS) and Unrestricted Densest Supermodular Set (UDSS) which allow negative and non-monotone functions.\n\nUsing classical results we observe that DSS, SFM, USSS, UDSS, and MNP are all equivalent under strongly polynomial-time reductions. This equivalence enables algorithmic cross-over: methods designed for one problem can be repurposed to solve others efficiently. In particular we use the perspective of the minimum norm point in the base polyhedron of a sub/supermodular function which, via Fujishige's results, yields the dense decomposition as a byproduct. Via this perspective we show that a recent converging heuristic for DSS, \\textsc{SuperGreedy++} [15, 29], and Wolfe\u2019s minimum norm point algorithm are both universal solvers for all of these problems. \n\nOn the theoretical front, we explain the observation made in recent work [39, 31] that \\textsc{SuperGreedy++} appears to work well even in settings beyond DSS. Surprisingly, we also show that this simple algorithm can be used for Submodular Function Minimization, including for example that it can act as an effective minimum $st$ cut algorithm. \n\nOn the empirical front, we explore the utility of several different algorithms including Fujishige-Wolfe min-norm point algorithm for recent problems. We conduct over 400 experiments across seven problem types and large-scale synthetic and real-world datasets (up to $\\approx 100$ million edges). Our results reveal that methods historically considered inefficient, such as convex-programming methods, flow-based solvers, and Fujishige-Wolfe\u2019s algorithm, outperform state-of-the-art task-specific baselines by orders of magnitude on concrete problems like HNSN [39]. These findings challenge prevailing assumptions and demonstrate that with the right framing, general optimization algorithms can be both scalable and state-of-the-art for supermodular and submodular ratio problems.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "EoebmBe9fG": {
        "venue": "ICLR 2025",
        "title": "Optimal Mistake Bounds for Transductive Online Learning",
        "link": "https://openreview.net/forum?id=EoebmBe9fG",
        "abstract": "We resolve a 30-year-old open problem concerning the power of unlabeled data in online learning by tightly quantifying the gap between transductive and standard online learning. We prove that for every concept class $\\mathcal{H}$ with Littlestone dimension $d$, the transductive mistake bound is at least $\\Omega(\\sqrt{d})$. This establishes an exponential improvement over previous lower bounds of $\\Omega(\\log \\log d)$, $\\Omega(\\sqrt{\\log d})$, and $\\Omega(\\log d)$, respectively due to Ben-David, Kushilevitz, and Mansour (1995, 1997) and Hanneke, Moran, and Shafer (2023). We also show that our bound is tight: for every $d$, there exists a class of Littlestone dimension $d$ with transductive mistake bound $O(\\sqrt{d})$. Our upper bound also improves the previous best known upper bound of $(2/3) \\cdot d$ from Ben-David et al. (1997). These results demonstrate a quadratic gap between transductive and standard online learning, thereby highlighting the benefit of advanced access to the unlabeled instance sequence. This stands in stark contrast to the PAC setting, where transductive and standard learning exhibit similar sample complexities.",
        "decision": "Accept (oral)",
        "review scores": [
            6,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "9XCyUFsm1H": {
        "venue": "ICLR 2025",
        "title": "OmniSync: Towards Universal Lip Synchronization via Diffusion Transformers",
        "link": "https://openreview.net/forum?id=9XCyUFsm1H",
        "abstract": "Lip synchronization is the task of aligning a speaker\u2019s lip movements in video with corresponding speech audio, and it is essential for creating realistic, expressive video content. \nHowever, existing methods often rely on reference frames and masked-frame inpainting, which limit their robustness to identity consistency, pose variations, facial occlusions, and stylized content. In addition, since audio signals provide weaker conditioning than visual cues, lip shape leakage from the original video will affect lip sync quality.\nIn this paper, we present OmniSync, a universal lip synchronization framework for diverse visual scenarios. Our approach introduces a mask-free training paradigm using Diffusion Transformer models for direct frame editing without explicit masks, enabling unlimited-duration inference while maintaining natural facial dynamics and preserving character identity.\nDuring inference, we propose a flow-matching-based progressive noise initialization to ensure pose and identity consistency, while allowing precise mouth-region editing. To address the weak conditioning signal of audio, we develop a Dynamic Spatiotemporal Classifier-Free Guidance (DS-CFG) mechanism that adaptively adjusts guidance strength over time and space.\nWe also establish the AIGC-LipSync Benchmark, the first evaluation suite for lip synchronization in diverse AI-generated videos. Extensive experiments demonstrate that OmniSync significantly outperforms prior methods in both visual quality and lip sync accuracy, achieving superior results in both real-world and AI-generated videos.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "5NkfjxMpWe": {
        "venue": "ICLR 2025",
        "title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding",
        "link": "https://openreview.net/forum?id=5NkfjxMpWe",
        "abstract": "Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding.  We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM\u2013VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about ''what'', ''where'', ''when'', and ''how'' of a video. We make our work fully reproducible by providing data, training recipes, code & models.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "1rUj9ZN6Bz": {
        "venue": "ICLR 2025",
        "title": "FlexOLMo: Open Language Models for Flexible Data Use",
        "link": "https://openreview.net/forum?id=1rUj9ZN6Bz",
        "abstract": "We introduce FlexOLMo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on private datasets, and (2) data-flexible inference, where these parameters along with their associated data can be easily included or excluded from model inferences with no further training. FlexOLMo employs a mixture-of-experts (MoE) architecture where each expert is trained independently on private datasets and later integrated through a new nonparametric routing without any joint training across datasets. FlexOLMo is trained on FLEXMIX, a corpus we curate comprising seven restricted sets, either real or realistic approximations, alongside publicly available datasets. We evaluate models with up to 37 billion parameters (20 billion active) on 31 diverse downstream tasks. We show that a general expert trained on public data can be effectively combined with independently trained experts from other data owners significantly benefiting from these restricted sets (an average 41% relative improvement) while allowing flexible opt-out at inference time (e.g., for users without appropriate licenses or permissions). Our approach also outperforms prior model merging methods by 10.1% on average and surpasses the standard MoE trained without data restrictions using the same training FLOPs. Altogether, FlexOLMo enables training on restricted data while keeping data local and supports fine-grained control of data access at inference.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "F0JzotXYgC": {
        "venue": "ICLR 2025",
        "title": "Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy",
        "link": "https://openreview.net/forum?id=F0JzotXYgC",
        "abstract": "A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \\in \\mathbb{R}^{n \\times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\\| (A + E)_p - A_p \\|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            6,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "mDjEKAwJOF": {
        "venue": "ICLR 2025",
        "title": "BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model",
        "link": "https://openreview.net/forum?id=mDjEKAwJOF",
        "abstract": "Unlocking deep and interpretable biological reasoning from complex genomic data remains a major AI challenge limiting scientific progress. While current DNA foundation models excel at representing sequences, they struggle with multi-step reasoning and lack transparent, biologically meaningful explanations. BioReason addresses this by tightly integrating a DNA foundation model with a large language model (LLM), enabling the LLM to directly interpret and reason over genomic information. Through supervised fine-tuning and reinforcement learning, BioReason learns to produce logical, biologically coherent deductions. It achieves major performance gains, boosting KEGG-based disease pathway prediction accuracy from 86% to 98% and improving variant effect prediction by an average of 15% over strong baselines. BioReason can reason over unseen biological entities and explain its decisions step by step, offering a transformative framework for interpretable, mechanistic AI in biology. All data, code, and checkpoints are available at [https://github.com/bowang-lab/BioReason](https://github.com/bowang-lab/BioReason).",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "cb0xbZ3APM": {
        "venue": "ICLR 2025",
        "title": "Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better",
        "link": "https://openreview.net/forum?id=cb0xbZ3APM",
        "abstract": "Vision-language-action (VLA) models provide a powerful approach to training control policies for physical systems, such as robots, by combining end-to-end learning with transfer of semantic knowledge from web-scale vision-language model (VLM) training. However, the constraints of real-time control are often at odds with the design of VLMs: the most powerful VLMs have tens or hundreds of billions of parameters, presenting an obstacle to real-time inference, and operate on discrete tokens rather than the continuous-valued outputs that are required for controlling robots. To address this challenge, recent VLA models have used specialized modules for efficient continuous control, such as action experts or continuous output heads, which typically require adding new untrained parameters to the pretrained VLM backbone. While these modules improve real-time and control capabilities, it remains an open question whether they preserve or degrade the semantic knowledge contained in the pretrained VLM, and what effect they have on the VLA training dynamics. In this paper, we study this question in the context of VLAs that include a continuous diffusion or flow matching action expert, showing that naively including such experts significantly harms both training speed and knowledge transfer. We provide an extensive analysis of various design choices, their impact on performance and knowledge transfer, and propose a technique for insulating the VLM backbone during VLA training that mitigates this issue. Videos are available at https://pi.website/research/knowledge_insulation and open-source model weights are available at https://github.com/Physical-Intelligence/openpi.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "KT8y9pFgJE": {
        "venue": "ICLR 2025",
        "title": "Fixed-Point RNNs: Interpolating from Diagonal to Dense",
        "link": "https://openreview.net/forum?id=KT8y9pFgJE",
        "abstract": "Linear recurrent neural networks (RNNs) and state-space models (SSMs) such as Mamba have become promising alternatives to softmax-attention as sequence mixing layers in Transformer architectures. Current models, however, do not exhibit the full state-tracking expressivity of RNNs because they rely on channel-wise (i.e. diagonal) sequence mixing. \nIn this paper, we investigate parameterizations of a large class of dense linear RNNs as fixed-points of parallelizable diagonal linear RNNs.\nThe resulting models can naturally trade expressivity for efficiency at a fixed number of parameters\nand achieve state-of-the-art results on the state-tracking benchmarks $A_5$ and $S_5$, while matching performance on copying and other tasks.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "6h7HLx1kbH": {
        "venue": "ICLR 2025",
        "title": "On Union-Closedness of Language Generation",
        "link": "https://openreview.net/forum?id=6h7HLx1kbH",
        "abstract": "We investigate language generation in the limit \u2013 a model by Kleinberg and Mullainathan and extended by Li, Raman, and Tewari. While Kleinberg and Mullainathan proved generation is possible for all countable collections, Li, Raman, and Tewari defined a hierarchy of generation notions (uniform, non-uniform, and generatable) and explored their feasibility for uncountable collections.\n    Our first set of results resolve two open questions of Li et al. by proving finite unions of generatable or non-uniformly generatable classes need not be generatable. These follow from a stronger result: there is non-uniformly generatable class and a uniformly generatable class  whose union is non-generatable.\n    This adds to the aspects along which language generation in the limit is different from traditional tasks in statistical learning theory like classification, which are closed under finite unions. \n    In particular, it implies that given two generators for different collections, one cannot combine them to obtain a single \"more powerful\" generator, prohibiting this notion of boosting. Our construction also addresses a third of Li et al.'s open questions on whether there are uncountable classes that are non-uniformly generatable and do not satisfy the eventually unbounded closure (EUC) condition introduced by Li et al.\n    Our approach utilizes carefully constructed classes along with a novel diagonalization argument that could be of independent interest in the growing area of language generation.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xKmlBQhgI4": {
        "venue": "ICLR 2025",
        "title": "Path-Enhanced Contrastive Learning for Recommendation",
        "link": "https://openreview.net/forum?id=xKmlBQhgI4",
        "abstract": "Collaborative filtering (CF) methods are now facing the challenge of data sparsity in recommender systems. In order to reduce the effect of data sparsity, researchers proposed contrastive learning methods to extract self-supervised signals from raw data. Contrastive learning methods address this problem by graph augmentation and maximizing the consistency of node representations between different augmented graphs. However, these methods tends to unintentionally distance the target node from its path nodes on the interaction path, thus limiting its effectiveness. In this regard, we propose a solution that uses paths as samples in the contrastive loss function. In order to obtain the path samples, we design a path sampling method. In addition to the contrast of the relationship between the target node and the nodes within the path (intra-path contrast), we also designed a method of contrasting the relationship between the paths (inter-path contrast) to better pull the target node and its path nodes closer to each other. We use Simplifying and Powering Graph Convolution Network (LightGCN) as the basis and combine with a new path-enhanced graph approach proposed for graph augmentation. It effectively improves the performance of recommendation models. Our proposed Path Enhanced Contrastive Loss (PECL) model replaces the common contrastive loss function with our novel loss function, showing significant performance improvement. Experiments on three real-world datasets demonstrate the effectiveness of our model.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            6,
            4
        ],
        "strengths": [],
        "weaknesses": []
    },
    "w1ihNiIBOc": {
        "venue": "ICLR 2025",
        "title": "Learning long range dependencies through time reversal symmetry breaking",
        "link": "https://openreview.net/forum?id=w1ihNiIBOc",
        "abstract": "Deep State Space Models (SSMs) reignite physics-grounded compute paradigms, as RNNs could natively be embodied into dynamical systems. This calls for dedicated learning algorithms obeying to core physical principles,  with efficient techniques to simulate these systems and guide their design. We propose \\emph{Recurrent Hamiltonian Echo Learning} (RHEL), an algorithm which provably computes loss gradients as finite differences of physical trajectories of non-dissipative, \\emph{Hamiltonian systems}. In ML terms, RHEL only requires three ``forward passes'' irrespective of model size, without explicit Jacobian computation, nor incurring any variance in the gradient estimation. Motivated by the potential to implement our algorithm in non-digital physical systems, we first \nintroduce RHEL in \\emph{continuous time} and demonstrate its formal equivalence with the continuous adjoint state method.\nTo facilitate the simulation of Hamiltonian systems trained by RHEL, we propose a \\emph{discrete-time} version of RHEL which is equivalent to Backpropagation Through Time (BPTT) when applied to a class of recurrent modules which we call \\emph{Hamiltonian Recurrent Units} (HRUs). This setting allows us to demonstrate the scalability of RHEL by generalizing these results to hierarchies of HRUs, which we call \\emph{Hamiltonian SSMs} (HSSMs). We apply RHEL to train HSSMs with linear and nonlinear dynamics on a variety of time-series tasks ranging from mid-range to long-range classification and regression with sequence length reaching $\\sim 50k$. We show that RHEL consistently matches the performance of BPTT across all models and tasks. This work opens new doors for the design of scalable, energy-efficient physical systems endowed with self-learning capabilities for sequence modelling.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "uQmUjgR8Er": {
        "venue": "ICLR 2025",
        "title": "Estimating Hitting Times Locally at Scale",
        "link": "https://openreview.net/forum?id=uQmUjgR8Er",
        "abstract": "Hitting times provide a fundamental measure of distance in random processes, quantifying the expected number of steps for a random walk starting at node $u$ to reach node $v$. They have broad applications across domains such as network centrality analysis, ranking and recommendation systems, and epidemiology.  \n\nIn this work, we develop local algorithms for estimating hitting times between a pair of vertices $u,v$ without accessing the full graph, overcoming scalability issues of prior global methods. Our first algorithm uses the key insight  that hitting time computations can be truncated at the meeting time of two independent random walks from $u$ and $v$. This leads to an efficient estimator analyzed via the Kronecker product graph and Markov Chain Chernoff bounds. We also present an algorithm extending the work of Peng et al. [2021] that introduces a novel adaptation of the spectral cutoff technique to account for the asymmetry of hitting times. This adaptation captures the directionality of the underlying random walk and requires non-trivial modifications to ensure accuracy and efficiency. In addition to the algorithmic upper bounds, we also provide tight asymptotic lower bounds. \n\nFinally, we reveal a connection between hitting time estimation and distribution testing, and we validate our algorithms using experiments on both real and synthetic data.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "rMhQBlhh4c": {
        "venue": "ICLR 2025",
        "title": "Adjoint Schr\u00f6dinger Bridge Sampler",
        "link": "https://openreview.net/forum?id=rMhQBlhh4c",
        "abstract": "Computational methods for learning to sample from the Boltzmann distribution\u2014where the target distribution is known only up to an unnormalized energy function\u2014have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known as _diffusion samplers_, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we propose **Adjoint Schr\u00f6dinger Bridge Sampler (ASBS)**, a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model\u2014the Schr\u00f6dinger Bridge\u2014which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions. Codes are available at https://github.com/facebookresearch/adjoint_samplers",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "qYDBgSeAlU": {
        "venue": "ICLR 2025",
        "title": "Replicable Distribution Testing",
        "link": "https://openreview.net/forum?id=qYDBgSeAlU",
        "abstract": "We initiate a systematic investigation of distribution testing in the framework of algorithmic replicability. Specifically, given independent samples from a collection of probability distributions, the goal is to characterize the sample complexity of replicably testing natural properties of the underlying distributions. On the algorithmic front, we develop new replicable algorithms for testing closeness and independence of discrete distributions. On the lower bound front, we develop a new methodology for proving sample complexity lower bounds for replicable testing that may be of broader interest. As an application of our technique, we establish near-optimal sample complexity lower bounds for replicable uniformity testing---answering an open question from prior work---and closeness testing.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "qAggjeV2JO": {
        "venue": "ICLR 2025",
        "title": "InfiGFusion: Graph-on-Logits Distillation via Efficient Gromov-Wasserstein for Model Fusion",
        "link": "https://openreview.net/forum?id=qAggjeV2JO",
        "abstract": "Recent advances in large language models (LLMs) have intensified efforts to fuse heterogeneous open-source models into a unified system that inherits their complementary strengths.  Existing logit-based fusion methods maintain inference efficiency but treat vocabulary dimensions independently, overlooking semantic dependencies encoded by cross-dimension interactions. These dependencies reflect how token types interact under a model's internal reasoning and are essential for aligning models with diverse generation behaviors. To explicitly model these dependencies, we propose \\textbf{InfiGFusion}, the first structure-aware fusion framework with a novel \\textit{Graph-on-Logits Distillation} (GLD) loss. Specifically, we retain the top-$k$ logits per output and aggregate their outer products across sequence positions to form a global co-activation graph, where nodes represent vocabulary channels and edges quantify their joint activations. To ensure scalability and efficiency, we design a sorting-based closed-form approximation that reduces the original $O(n^4)$ cost of Gromov-Wasserstein distance to $O(n \\log n)$, with provable approximation guarantees. Experiments across multiple fusion settings show that GLD consistently improves fusion quality and stability. InfiGFusion outperforms SOTA models and fusion baselines across 11 benchmarks spanning reasoning, coding, and mathematics. It shows particular strength in complex reasoning tasks, with +35.6 improvement on Multistep Arithmetic and +37.06 on Causal Judgement over SFT, demonstrating superior multi-step and relational inference.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "oHB4Ee77uG": {
        "venue": "ICLR 2025",
        "title": "CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring",
        "link": "https://openreview.net/forum?id=oHB4Ee77uG",
        "abstract": "As AI models are deployed with increasing autonomy, it is important to ensure they do not take harmful actions unnoticed. As a potential mitigation, we investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor model continuously oversees the intermediate reasoning steps of a more powerful but untrusted model. We compare CoT monitoring to action-only monitoring, where only final outputs are reviewed, in a red-teaming setup where the untrusted model is instructed to pursue harmful side tasks while completing a coding problem. We find that while CoT monitoring is more effective than overseeing only model outputs in scenarios where action-only monitoring fails to reliably identify sabotage, reasoning traces can contain misleading rationalizations that deceive the CoT monitors, reducing performance in obvious sabotage cases. To address this, we introduce a hybrid protocol that independently scores model reasoning and actions, and combines them using a weighted average. Our hybrid monitor consistently outperforms both CoT and action-only monitors across all tested models and tasks, with detection rates twice higher than action-only monitoring for subtle deception scenarios.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "nlQRra0OLH": {
        "venue": "ICLR 2025",
        "title": "A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking",
        "link": "https://openreview.net/forum?id=nlQRra0OLH",
        "abstract": "The real world is dynamic, yet most image fusion methods process static frames independently, ignoring temporal correlations in videos and leading to flickering and temporal inconsistency. To address this, we propose Unified Video Fusion (UniVF), a novel and unified framework for video fusion that leverages multi-frame learning and optical flow-based feature warping for informative, temporally coherent video fusion. To support its development, we also introduce Video Fusion Benchmark (VF-Bench), the first comprehensive benchmark covering four video fusion tasks: multi-exposure, multi-focus, infrared-visible, and medical fusion. VF-Bench provides high-quality, well-aligned video pairs obtained through synthetic data generation and rigorous curation from existing datasets, with a unified evaluation protocol that jointly assesses the spatial quality and temporal consistency of video fusion. Extensive experiments show that UniVF achieves state-of-the-art results across all tasks on VF-Bench. Project page: [vfbench.github.io](https://vfbench.github.io).",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "n8AvXKcCeR": {
        "venue": "ICLR 2025",
        "title": "GenColor: Generative and Expressive Color Enhancement with Pixel-Perfect Texture Preservation",
        "link": "https://openreview.net/forum?id=n8AvXKcCeR",
        "abstract": "Color enhancement is a crucial yet challenging task in digital photography. It demands methods that are (i) expressive enough for fine-grained adjustments, (ii) adaptable to diverse inputs, and (iii) able to preserve texture. Existing approaches typically fall short in at least one of these aspects, yielding unsatisfactory results. We propose GenColor, a novel diffusion-based framework for sophisticated, texture-preserving color enhancement. GenColor reframes the task as conditional image generation. Leveraging ControlNet and a tailored training scheme, it learns advanced color transformations that adapt to diverse lighting and content. We train GenColor on ARTISAN, our newly collected large-scale dataset of 1.2M high-quality photographs specifically curated for enhancement tasks. To overcome texture preservation limitations inherent in diffusion models, we introduce a color-transfer network with a novel degradation scheme that simulates texture\u2013color relationships. This network achieves pixel-perfect texture preservation while enabling fine-grained color matching with the diffusion-generated reference images. Extensive experiments show that GenColor produces visually compelling results comparable to those of expert colorists and surpasses state-of-the-art methods in both subjective and objective evaluations. We have released the code and dataset.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "n3armuTFit": {
        "venue": "ICLR 2025",
        "title": "Orient Anything V2: Unifying Orientation and Rotation Understanding",
        "link": "https://openreview.net/forum?id=n3armuTFit",
        "abstract": "This work presents Orient Anything V2, an enhanced foundation model for unified understanding of object 3D orientation and rotation from single or paired images. Building upon Orient Anything V1, which defines orientation via a single unique front face, V2 extends this capability to handle objects with diverse rotational symmetries and directly estimate relative rotations. These improvements are enabled by four key innovations: 1) Scalable 3D assets synthesized by generative models, ensuring broad category coverage and balanced data distribution; 2) An efficient, model-in-the-loop annotation system that robustly identifies 0 to N valid front faces for each object; 3) A symmetry-aware, periodic distribution fitting objective that captures all plausible front-facing orientations, effectively modeling object rotational symmetry; 4) A multi-frame architecture that directly predicts relative object rotations. Extensive experiments show that Orient Anything V2 achieves state-of-the-art zero-shot performance on orientation estimation, 6DoF pose estimation, and object symmetry recognition across 11 widely used benchmarks. The model demonstrates strong generalization, significantly broadening the applicability of orientation estimation in diverse downstream tasks.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "ls5L4IMEwt": {
        "venue": "ICLR 2025",
        "title": "E2Former: An Efficient and Equivariant Transformer with Linear-Scaling Tensor Products",
        "link": "https://openreview.net/forum?id=ls5L4IMEwt",
        "abstract": "Equivariant Graph Neural Networks (EGNNs) have demonstrated significant success in modeling microscale systems, including those in chemistry, biology and materials science. However, EGNNs face substantial computational challenges due to the high cost of constructing edge features via spherical tensor products, making them almost impractical for large-scale systems. \nTo address this limitation, we introduce E2Former, an equivariant and efficient transformer architecture that incorporates a Wigner $6j$ convolution (Wigner $6j$ Conv). By shifting the computational burden from edges to nodes, Wigner $6j$ Conv reduces the complexity from $O(| \\mathcal{E}|)$ to  $O(| \\mathcal{V}|)$ while preserving both the model's expressive power and rotational equivariance.\nWe show that this approach achieves a 7x\u201330x speedup compared to conventional $\\mathrm{SO}(3)$ convolutions. Furthermore, our empirical results demonstrate that the derived E2Former mitigates the computational challenges of existing approaches without compromising the ability to capture detailed geometric information. This development could suggest a promising direction for scalable molecular modeling.",
        "decision": "Accept (spotlight)",
        "review scores": [
            4,
            5,
            6,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "lMhNrt0Bnm": {
        "venue": "ICLR 2025",
        "title": "VoxDet: Rethinking 3D Semantic Scene Completion as Dense Object Detection",
        "link": "https://openreview.net/forum?id=lMhNrt0Bnm",
        "abstract": "Semantic Scene Completion (SSC) aims to reconstruct the 3D geometry and semantics of the surrounding environment. With dense voxel labels, prior works typically formulate SSC as a *dense segmentation task*, independently classifying each voxel. However, this paradigm neglects critical instance-centric discriminability, leading to instance-level incompleteness and adjacent ambiguities. To address this, we highlight a \"free lunch\" of SSC labels: the voxel-level class label has implicitly told the instance-level insight, which is ever-overlooked by the community. Motivated by this observation, we first introduce a training-free **Voxel-to-Instance (VoxNT) trick**: a simple yet effective method that freely converts voxel-level class labels into instance-level offset labels. Building on this, we further propose **VoxDet**, an instance-centric framework that reformulates the voxel-level SSC as *dense object detection* by decoupling it into two sub-tasks: offset regression and semantic prediction. Specifically, based on the lifted 3D volume, VoxDet first uses (a) Spatially-decoupled Voxel Encoder to generate disentangled feature volumes for the two sub-tasks, which learn task-specific spatial deformation in the densely projected tri-perceptive space. Then, we deploy (b) Task-decoupled Dense Predictor to address SSC via dense detection. Here, we first regress a 4D offset field to estimate distances (6 directions) between voxels and the corresponding object boundaries in the voxel space. The regressed offsets are then used to guide the instance-level aggregation in the classification branch, achieving instance-aware scene completion. VoxDet can be deployed on both camera and LiDAR input and jointly achieves state-of-the-art results on both benchmarks, which gives 63.0 IoU on the SemanticKITTI test set, **ranking 1$^{st}$** on the online leaderboard.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "jut5q3UYRz": {
        "venue": "ICLR 2025",
        "title": "Reverse-Annealed Sequential Monte Carlo for Efficient Bayesian Optimal Experiment Design",
        "link": "https://openreview.net/forum?id=jut5q3UYRz",
        "abstract": "Expected information gain (EIG) is a crucial quantity in Bayesian optimal experimental design (BOED), quantifying how useful an experiment is by the amount we expect the posterior to differ from the prior.\nHowever, evaluating the EIG can be computationally expensive since it generally requires estimating the posterior normalizing constant.\nIn this work, we leverage two idiosyncrasies of BOED to improve efficiency of EIG estimation via sequential Monte Carlo (SMC).\nFirst, in BOED we simulate the data and thus know the true underlying parameters.\nSecond, we ultimately care about the EIG, not the individual normalizing constants.\nOften we observe that the Monte Carlo variance of standard SMC estimators for the normalizing constant of a single dataset are significantly lower than the variance of the normalizing constants across datasets; the latter thus contributes the majority of the variance for EIG estimates.\nThis suggests the potential to slightly increase variance while drastically decreasing computation time by reducing the SMC population size, which leads us to an EIG-specific SMC estimator that starts with a only a single sample from the posterior and tempers \\textit{backwards} towards the prior. Using this single-sample estimator, which we call reverse-annealed SMC (RA-SMC), we show that it is possible to estimate EIG with orders of magnitude fewer likelihood evaluations in three models: a four-dimensional spring-mass, a six-dimensional Johnson-Cook model and a four-dimensional source-finding problem.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "i5WnXNjwbR": {
        "venue": "ICLR 2025",
        "title": "ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression",
        "link": "https://openreview.net/forum?id=i5WnXNjwbR",
        "abstract": "The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance on texture. Code is available at https://github.com/tomburgert/feature-reliance.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "hguaupzLCU": {
        "venue": "ICLR 2025",
        "title": "Horizon Reduction Makes RL Scalable",
        "link": "https://openreview.net/forum?id=hguaupzLCU",
        "abstract": "In this work, we study the scalability of offline reinforcement learning (RL) algorithms. In principle, a truly scalable offline RL algorithm should be able to solve any given problem, regardless of its complexity, given sufficient data, compute, and model capacity. We investigate if and how current offline RL algorithms match up to this promise on diverse, challenging, previously unsolved tasks, using datasets up to 1000\u00d7 larger than typical offline RL datasets. We observe that despite scaling up data, many existing offline RL algorithms exhibit poor scaling behavior, saturating well below the maximum performance. We hypothesize that the horizon is the main cause behind the poor scaling of offline RL. We empirically verify this hypothesis through several analysis experiments, showing that long horizons indeed present a fundamental barrier to scaling up offline RL. We then show that various horizon reduction techniques substantially enhance scalability on challenging tasks. Based on our insights, we also introduce a minimal yet scalable method named SHARSA that effectively reduces the horizon. SHARSA achieves the best asymptotic performance and scaling behavior among our evaluation methods, showing that explicitly reducing the horizon unlocks the scalability of offline RL.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "hdT7UC7oG6": {
        "venue": "ICLR 2025",
        "title": "Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian Optimization",
        "link": "https://openreview.net/forum?id=hdT7UC7oG6",
        "abstract": "Bayesian Optimization (BO) has the potential to solve various combinatorial tasks, ranging from materials science to neural architecture search. However, BO requires specialized kernels to effectively model combinatorial domains. Recent efforts have introduced several combinatorial kernels, but the relationships among them are not well understood. To bridge this gap, we develop a unifying framework based on heat kernels, which we derive in a systematic way and express as simple closed-form expressions. Using this framework, we prove that many successful combinatorial kernels are either related or equivalent to heat kernels, and validate this theoretical claim in our experiments. Moreover, our analysis confirms and extends the results presented in Bounce: certain algorithms' performance decreases substantially when the unknown optima of the function do not have a certain structure. In contrast, heat kernels are not sensitive to the location of the optima. Lastly, we show that a fast and simple pipeline, relying on heat kernels, is able to achieve state-of-the-art results, matching or even outperforming certain slow or complex algorithms.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "gxfusMqPIs": {
        "venue": "ICLR 2025",
        "title": "Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization",
        "link": "https://openreview.net/forum?id=gxfusMqPIs",
        "abstract": "This paper addresses the Bayesian optimization problem (also referred to as the Bayesian setting of the Gaussian process bandit), where the learner seeks to minimize the regret under a function drawn from a known Gaussian process (GP). \nUnder a Mat\\'ern kernel with some extent of smoothness, we show that the Gaussian process upper confidence bound (GP-UCB) algorithm achieves $\\tilde{O}(\\sqrt{T})$ cumulative regret with high probability. Furthermore, our analysis yields $O(\\sqrt{T \\ln^2 T})$ regret under a squared exponential kernel. These results fill the gap between the existing regret upper bound of GP-UCB and the current best upper bound provided by Scarlett [2018]. The key idea in our proof is to capture the concentration behavior of the input sequence realized by GP-UCB, enabling us to handle GP's information gain in a refined manner.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "bP5cU0OYSn": {
        "venue": "ICLR 2025",
        "title": "Fast Projection-Free Approach (without Optimization Oracle) for Optimization over Compact Convex Set",
        "link": "https://openreview.net/forum?id=bP5cU0OYSn",
        "abstract": "Projection-free first-order methods, e.g., the celebrated Frank-Wolfe (FW) algorithms, have emerged as powerful tools for optimization over simple convex sets such as polyhedra, because of their scalability, fast convergence, and iteration-wise feasibility without costly projections. \nHowever, extending these methods effectively to general compact convex sets remains challenging and largely open, as FW methods rely on expensive linear optimization oracles (LOO), while penalty-based methods often struggle with poor feasibility. \nWe tackle this open challenge by presenting **Hom-PGD**, a novel projection-free method without expensive (optimization) oracles. \nOur method constructs a homeomorphism between the convex constraint set and a unit ball, transforming the original problem into an equivalent ball-constrained formulation, thus enabling efficient gradient-based optimization while preserving the original problem structure. \nWe prove that Hom-PGD attains *optimal* convergence rates matching gradient descent with constant step-size to find an $\\epsilon$-approximate (stationary) solution: $\\mathcal{O}(\\log (1/\\epsilon))$ for strongly convex objectives, $\\mathcal{O}(\\epsilon^{-1})$ for convex objectives, \nand $\\mathcal{O}(\\epsilon^{-2})$ for non-convex objectives. \nMeanwhile, Hom-PGD enjoys a low per-iteration complexity of $\\mathcal{O}(n^2)$, without expensive oracles like LOO or projection, where $n$ is the input size. \nOur framework further extends to certain non-convex sets, broadening its applicability in practical optimization scenarios with complex constraints. Extensive numerical experiments demonstrate that Hom-PGD achieves comparable convergence rates to state-of-the-art projection-free methods, while significantly reducing per-iteration runtime  (up to 5 orders of magnitude faster) and thus the total problem-solving time.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "bA02DmQN5d": {
        "venue": "ICLR 2025",
        "title": "Vision Transformers Don't Need Trained Registers",
        "link": "https://openreview.net/forum?id=bA02DmQN5d",
        "abstract": "We investigate the mechanism underlying a previously identified phenomenon in Vision Transformers -- the emergence of high-norm tokens that lead to noisy attention maps (Darcet et al., 2024). We observe that in multiple models (e.g., CLIP, DINOv2), a sparse set of neurons is responsible for concentrating high-norm activations on outlier tokens, leading to irregular attention patterns and degrading downstream visual processing. While the existing solution for removing these outliers involves retraining models from scratch with additional learned $\\textit{register tokens}$, we use our findings to create a training-free approach to mitigate these artifacts. By shifting the high-norm activations from our discovered $\\textit{register neurons}$ into an additional untrained token, we can mimic the effect of register tokens on a model already trained without registers. We demonstrate that our method produces cleaner attention and feature maps, enhances performance over base models across multiple downstream visual tasks, and achieves results comparable to models explicitly trained with register tokens. We then extend test-time registers to off-the-shelf vision-language models, yielding cleaner attention-based, text-to-image attribution. Finally, we outline a simple mathematical model that reflects the observed behavior of register neurons and high norm tokens. Our results suggest that test-time registers effectively take on the role of register tokens at test-time, offering a training-free solution for any pre-trained model released without them.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "b387eWFV3V": {
        "venue": "ICLR 2025",
        "title": "Generalization Bounds for Kolmogorov-Arnold Networks (KANs) and Enhanced KANs with Lower Lipschitz Complexity",
        "link": "https://openreview.net/forum?id=b387eWFV3V",
        "abstract": "Kolmogorov-Arnold Networks (KANs) have demonstrated remarkable expressive capacity and predictive power in symbolic learning. However, existing generalization errors of KANs primarily focus on approximation errors while neglecting estimation errors, leading to a suboptimal bias-variance trade-off and poor generalization performance. Meanwhile, the unclear generalization mechanism hinders the design of more effective KANs variants. As the authors of KANs highlighted, they ``would like to explore ways to restrict KANs' hypothesis space so that they can achieve good performance''. To address these challenges, we explore the generalization mechanism of KANs and design more effective KANs with lower model complexity and better generalization. We define \\textit{Lipschitz complexity} as the first structural measure for deep functions represented by KANs and derive novel generalization bounds based on \\textit{Lipschitz complexity}, establishing a theoretical foundation for understanding their generalization behavior. To reduce \\textit{Lipschitz complexity} and boost the generalization mechanism of KANs, we propose Lipschitz-Enhanced KANs ($\\textbf{LipKANs}$) by integrating the Lip layer and pioneering the $L_{1.5}$-regularized loss, contributing to tighter generalization bounds. Empirical experiments validate that the proposed LipKANs enhance the generalization mechanism of KANs when modeling complex distributions. We hope our theoretical bounds and LipKANs lay a foundation for the future development of KANs.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "ZwCVFBFUFb": {
        "venue": "ICLR 2025",
        "title": "QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training",
        "link": "https://openreview.net/forum?id=ZwCVFBFUFb",
        "abstract": "Clinical decision\u2011making routinely demands reasoning over heterogeneous data, yet existing multimodal language models (MLLMs) remain largely vision\u2011centric and fail to generalize across clinical specialties. To bridge this gap, we introduce QoQ-Med-7B/32B, the first open generalist clinical foundation model that jointly reasons across medical images, time\u2011series signals, and text reports. QoQ-Med is trained with Domain\u2011aware Relative Policy Optimization (DRPO), a novel reinforcement\u2011learning objective that hierarchically scales normalized rewards according to domain rarity and modality difficulty, mitigating performance imbalance caused by skewed clinical data distributions. Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains, we show that DRPO training boosts diagnostic performance by 43% in macro\u2011F1 on average across all visual domains as compared to other critic-free training methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation data, it is able to highlight salient regions related to the diagnosis, with an IoU 10x higher than open models while reaching the performance of OpenAI o4-mini. To foster reproducibility and downstream research, we release (i) the full model weights, (ii) the modular training pipeline, and (iii) all intermediate reasoning traces.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "YXSKYFZweV": {
        "venue": "ICLR 2025",
        "title": "Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators",
        "link": "https://openreview.net/forum?id=YXSKYFZweV",
        "abstract": "Operator learning is a powerful paradigm for solving partial differential equations, with Fourier Neural Operators serving as a widely adopted foundation. However, FNOs face significant scalability challenges due to overparameterization and offer no native uncertainty quantification -- a key requirement for reliable scientific and engineering applications. Instead, neural operators rely on post hoc UQ methods that ignore geometric inductive biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator parametrization with uncertainty quantification. Inspired by the structure of the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a dimensionality-independent diffusion multiplier that has a single learnable time parameter per channel, drastically reducing parameter count and memory footprint without compromising predictive performance. By defining priors over those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield spatially correlated outputs and calibrated uncertainty estimates. Our method achieves competitive or superior performance across several PDE benchmarks while providing efficient uncertainty quantification.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "WCRPgBpbcA": {
        "venue": "ICLR 2025",
        "title": "A multiscale analysis of mean-field transformers in the moderate interaction regime",
        "link": "https://openreview.net/forum?id=WCRPgBpbcA",
        "abstract": "In this paper, we study the evolution of tokens through the depth of encoder-only transformer models at inference time by modeling them as a system of particles interacting in a mean-field way and studying the corresponding dynamics. More specifically, we consider this problem in the moderate interaction regime, where the number $N$ of tokens is large and the inverse temperature parameter $\\beta$ of the model scales together with $N$. In this regime, the dynamics of the system displays a multiscale behavior: a fast phase, where the token empirical measure collapses on a low-dimensional space, an intermediate phase, where the measure further collapses into clusters, and a slow one, where such clusters sequentially merge into a single one. We provide a rigorous characterization of the limiting dynamics in each of these phases and prove convergence in the above mentioned limit, exemplifying our results with some simulations.",
        "decision": "Accept (oral)",
        "review scores": [
            4,
            5,
            6,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "Vqj65VeDOu": {
        "venue": "ICLR 2025",
        "title": "Stable Gradients for Stable Learning at Scale in Deep Reinforcement Learning",
        "link": "https://openreview.net/forum?id=Vqj65VeDOu",
        "abstract": "Scaling deep reinforcement learning networks is challenging and often results in degraded performance, yet the root causes of this failure mode remain poorly understood. Several recent works have proposed mechanisms to address this, but they are often complex and fail to highlight the causes underlying this difficulty. In this work, we conduct a series of empirical analyses which suggest that the combination of non-stationarity with gradient pathologies, due to suboptimal architectural choices, underlie the challenges of scale. We propose a series of direct interventions that stabilize gradient flow, enabling robust performance across a range of network depths and widths. Our interventions are simple to implement and compatible with well-established algorithms, and result in an effective mechanism that enables strong performance even at large scales. We validate our findings on a variety of agents and suites of environments.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "UfFTBEsLgI": {
        "venue": "ICLR 2025",
        "title": "The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning",
        "link": "https://openreview.net/forum?id=UfFTBEsLgI",
        "abstract": "Entropy minimization (EM) trains the model to concentrate even more probability mass on its most confident outputs. \nWe show that this simple objective alone, without any labeled data, can substantially improve large language models\u2019 (LLMs) performance on challenging math, physics, and coding tasks. We explore three approaches: (1) EM-FT minimizes token-level entropy similarly to instruction finetuning, but on unlabeled outputs drawn from the model; (2) EM-RL: reinforcement learning with negative entropy as the only reward to maximize; (3) EM-INF: inference-time logit adjustment to reduce entropy without any training data or parameter updates. \nOn Qwen-7B, EM-RL, without any labeled data, achieves comparable or better performance than strong RL baselines such as GRPO and RLOO that are trained on 60K labeled examples. Furthermore, EM-INF enables Qwen-32B to match or exceed the performance of proprietary models like GPT-4o, Claude 3 Opus, and Gemini 1.5 Pro on the challenging SciCode benchmark, while being 3x more efficient than self-consistency and sequential refinement. Our findings reveal that many pretrained LLMs possess previously underappreciated reasoning capabilities that can be effectively elicited through entropy minimization alone, without any labeled data or even any parameter updates.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            6,
            6,
            4
        ],
        "strengths": [],
        "weaknesses": []
    },
    "TeocEZCWnr": {
        "venue": "ICLR 2025",
        "title": "Exact and Linear Convergence for Federated Learning under Arbitrary Client Participation is Attainable",
        "link": "https://openreview.net/forum?id=TeocEZCWnr",
        "abstract": "This work tackles the fundamental challenges in Federated Learning (FL) posed by arbitrary client participation and data heterogeneity, prevalent characteristics in practical FL settings.  It is well-established that popular FedAvg-style algorithms struggle with exact convergence and can suffer from slow convergence rates since a decaying learning rate is required to mitigate these scenarios. To address these issues, we introduce the concept of stochastic matrix and the corresponding time-varying graphs as a novel modeling tool to accurately capture the dynamics of arbitrary client participation and the local update procedure. Leveraging this approach, we offer a fresh perspective on designing FL algorithms, provide a rigorous quantitative analysis of the limitations inherent in the FedAvg algorithm, and present FOCUS, Federated Optimization with Exact Convergence via Push-pull Strategy, a provably convergent algorithm designed to effectively overcome the previously mentioned two challenges. More specifically, we provide a rigorous proof demonstrating that FOCUS achieves exact convergence with a linear rate regardless of the arbitrary client participation, establishing it as the first work to demonstrate this significant result.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "SgQAleMecy": {
        "venue": "ICLR 2025",
        "title": "Optimal and Provable Calibration in High-Dimensional Binary Classification: Angular Calibration and Platt Scaling",
        "link": "https://openreview.net/forum?id=SgQAleMecy",
        "abstract": "We study the fundamental problem of calibrating a linear binary classifier of the form \\(\\sigma(\\hat{w}^\\top x)\\), where the feature vector \\(x\\) is Gaussian, \\(\\sigma\\) is a link function, and \\(\\hat{w}\\) is an estimator of the true linear weight $w^\\star$. By interpolating with a noninformative \\emph{chance classifier}, we construct a well-calibrated predictor whose interpolation weight depends on the angle \\(\\angle(\\hat{w}, w_\\star)\\) between the estimator \\(\\hat{w}\\) and the true linear weight \\(w_\\star\\). We establish that this angular calibration approach is provably well-calibrated in a high-dimensional regime where the number of samples and features both diverge, at a comparable rate. The angle \\(\\angle(\\hat{w}, w_\\star)\\)  can be consistently estimated. Furthermore, the resulting predictor is uniquely \\emph{Bregman-optimal}, minimizing the Bregman divergence to the true label distribution within a suitable class of calibrated predictors.\nOur work is the first to provide a calibration strategy that satisfies both calibration and optimality properties provably in high dimensions. Additionally, we identify conditions under which a classical Platt-scaling predictor converges to our Bregman-optimal calibrated solution. Thus, Platt-scaling also inherits these desirable properties provably in high dimensions.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "RE97LT26w8": {
        "venue": "ICLR 2025",
        "title": "True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics",
        "link": "https://openreview.net/forum?id=RE97LT26w8",
        "abstract": "Complex, temporally evolving phenomena, from climate to brain activity, are governed by dynamical systems (DS). DS reconstruction (DSR) seeks to infer generative surrogate models of these from observed data, reproducing their long-term behavior. Existing DSR approaches require purpose-training for any new system observed, lacking the zero-shot and in-context inference capabilities known from LLMs. Here we introduce *DynaMix*, a novel multivariate ALRNN-based mixture-of-experts architecture pre-trained for DSR, the first DSR model able to generalize zero-shot to out-of-domain DS. Just from a provided context signal, without any re-training, DynaMix faithfully forecasts the long-term evolution of novel DS where existing time series (TS) foundation models, like Chronos, fail -- at a fraction of the number of parameters (0.1%) and orders of magnitude faster inference times. DynaMix outperforms TS foundation models in terms of long-term statistics, and often also short-term forecasts, even on real-world time series, like traffic or weather data, typically used for training and evaluating TS models, *but not at all part of DynaMix' training corpus*. We illustrate some of the failure modes of TS models for DSR problems, and conclude that models built on DS principles may bear a huge potential also for advancing the TS prediction field.",
        "decision": "Accept (poster)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "PtGMadeONU": {
        "venue": "ICLR 2025",
        "title": "Taccel: Scaling Up Vision-based Tactile Robotics via High-performance GPU Simulation",
        "link": "https://openreview.net/forum?id=PtGMadeONU",
        "abstract": "Tactile sensing is crucial for achieving human-level robotic capabilities in manipulation tasks. As a promising solution, Vision-based Tactile Sensors (VBTSs) offer high spatial resolution and cost-effectiveness, but present unique challenges in robotics for their complex physical characteristics and visual signal processing requirements. The lack of efficient and accurate simulation tools for VBTSs has significantly limited the scale and scope of tactile robotics research. We present Taccel, a high-performance simulation platform that integrates Incremental Potential Contact (IPC) and Affine Body Dynamics (ABD) to model robots, tactile sensors, and objects with both accuracy and unprecedented speed, achieving a total of 915 FPS with 4096 parallel environments. Unlike previous simulators that operate at sub-real-time speeds with limited parallelization, Taccel provides precise physics simulation and realistic tactile signals while supporting flexible robot-sensor configurations through user-friendly APIs. Through extensive validation in object recognition, robotic grasping, and articulated object manipulation, we demonstrate precise simulation and successful sim-to-real transfer. These capabilities position Taccel as a powerful tool for scaling up tactile robotics research and development, potentially transforming how robots interact with and understand their physical environment.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            6,
            4
        ],
        "strengths": [],
        "weaknesses": []
    },
    "OzdAnGHEPx": {
        "venue": "ICLR 2025",
        "title": "Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables",
        "link": "https://openreview.net/forum?id=OzdAnGHEPx",
        "abstract": "Recently, deep learning-based pan-sharpening algorithms have achieved notable advancements over traditional methods. However, deep learning-based methods incur substantial computational overhead during inference, especially with large images. This excessive computational demand limits the applicability of these methods in real-world scenarios, particularly in the absence of dedicated computing devices such as GPUs and TPUs. To address these challenges, we propose Pan-LUT, a novel learnable look-up table (LUT) framework for pan-sharpening that strikes a balance between performance and computational efficiency for large remote sensing images. Our method makes it possible to process 15K$\\times$15K remote sensing images on a 24GB GPU. To finely control the spectral transformation, we devise the PAN-guided look-up table (PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained spatial details, we introduce the spatial details look-up table (SDLUT). Furthermore, to adaptively aggregate channel information for generating high-resolution multispectral images, we design an adaptive output look-up table (AOLUT). Our model contains fewer than 700K parameters and processes a 9K$\\times$9K image in under 1 ms using one RTX 2080 Ti GPU, demonstrating significantly faster performance compared to other methods. Experiments reveal that Pan-LUT efficiently processes large remote sensing images in a lightweight manner, bridging the gap to real-world applications. Furthermore, our model surpasses SOTA methods in full-resolution scenes under real-world conditions, highlighting its effectiveness and efficiency. We also extend our method to general image fusion tasks.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "ONc9vWkwCp": {
        "venue": "ICLR 2025",
        "title": "On the necessity of adaptive regularisation: Optimal anytime online learning on $\\boldsymbol{\\ell_p}$-balls",
        "link": "https://openreview.net/forum?id=ONc9vWkwCp",
        "abstract": "We study online convex optimization on $\\ell_p$-balls in $\\mathbb{R}^d$ for $p > 2$. While always sub-linear, the optimal regret exhibits a shift between the high-dimensional setting ($d > T$), when the dimension $d$ is greater than the time horizon $T$ and the low-dimensional setting ($d \\leq T$). We show that Follow-the-Regularised-Leader (FTRL) with time-varying regularisation which is adaptive to the dimension regime is anytime optimal for all dimension regimes. Motivated by this, we ask whether it is possible to obtain anytime optimality of FTRL with fixed non-adaptive regularisation. Our main result establishes that for separable regularisers, adaptivity in the regulariser is necessary, and that any fixed regulariser will be sub-optimal in one of the two dimension regimes. Finally, we provide lower bounds which rule out sub-linear regret bounds for the linear bandit problem in sufficiently high-dimension for all $\\ell_p$-balls with $p \\geq 1$.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "N1KPOlcN6P": {
        "venue": "ICLR 2025",
        "title": "Flow Equivariant Recurrent Neural Networks",
        "link": "https://openreview.net/forum?id=N1KPOlcN6P",
        "abstract": "Data arrives at our senses as a continuous stream, smoothly transforming from one instant to the next. These smooth transformations can be viewed as continuous symmetries of the environment that we inhabit, defining equivalence relations between stimuli over time. In machine learning, neural network architectures that respect symmetries of their data are called equivariant and have provable benefits in terms of generalization ability and sample efficiency. To date, however, equivariance has been considered only for static transformations and feed-forward networks, limiting its applicability to sequence models, such as recurrent neural networks (RNNs), and corresponding time-parameterized sequence transformations. In this work, we extend equivariant network theory to this regime of 'flows' -- one-parameter Lie subgroups capturing natural transformations over time, such as visual motion. We begin by showing that standard RNNs are generally not flow equivariant: their hidden states fail to transform in a geometrically structured manner for moving stimuli. We then show how flow equivariance can be introduced, and demonstrate that these models significantly outperform their non-equivariant counterparts in terms of training speed, length generalization, and velocity generalization, on both next step prediction and sequence classification. We present this work as a first step towards building sequence models that respect the time-parameterized symmetries which govern the world around us.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "M6l3pyvUfr": {
        "venue": "ICLR 2025",
        "title": "TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence",
        "link": "https://openreview.net/forum?id=M6l3pyvUfr",
        "abstract": "Molecular property prediction aims to learn representations that map chemical structures to functional properties. While multimodal learning has emerged as a powerful paradigm to learn molecular representations, prior works have largely overlooked textual and taxonomic information of molecules for representation learning. We introduce TRIDENT, a novel framework that integrates molecular SMILES, textual descriptions, and taxonomic functional annotations to learn rich molecular representations. To achieve this, we curate a comprehensive dataset of molecule-text pairs with structured, multi-level functional annotations. Instead of relying on conventional contrastive loss, TRIDENT employs a volume-based alignment objective to jointly align tri-modal features at the global level, enabling soft, geometry-aware alignment across modalities. Additionally, TRIDENT introduces a novel local alignment objective that captures detailed relationships between molecular substructures and their corresponding sub-textual descriptions. A momentum-based mechanism dynamically balances global and local alignment, enabling the model to learn both broad functional semantics and fine-grained structure-function mappings. TRIDENT achieves state-of-the-art performance on 18 downstream tasks, demonstrating the value of combining SMILES, textual, and taxonomic functional annotations for molecular property prediction. Our code and data are available at https://github.com/uta-smile/TRIDENT.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "M44RvNMZs4": {
        "venue": "ICLR 2025",
        "title": "Vector Quantization in the Brain: Grid-like Codes in World Models",
        "link": "https://openreview.net/forum?id=M44RvNMZs4",
        "abstract": "We propose Grid-like Code Quantization (GCQ), a brain-inspired method for compressing observation-action sequences into discrete representations using grid-like patterns in attractor dynamics. Unlike conventional vector quantization approaches that operate on static inputs, GCQ performs spatiotemporal compression through an action-conditioned codebook, where codewords are derived from continuous attractor neural networks and dynamically selected based on actions. This enables GCQ to jointly compress space and time, serving as a unified world model. The resulting representation supports long-horizon prediction, goal-directed planning, and inverse modeling. Experiments across diverse tasks demonstrate GCQ's effectiveness in compact encoding and downstream performance. Our work offers both a computational tool for efficient sequence modeling and a theoretical perspective on the formation of grid-like codes in neural systems.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "KnqiC0znVF": {
        "venue": "ICLR 2025",
        "title": "Large Language Diffusion Models",
        "link": "https://openreview.net/forum?id=KnqiC0znVF",
        "abstract": "The capabilities of large language models (LLMs) are widely regarded as relying on autoregressive models (ARMs). We challenge this notion by introducing *LLaDA*, a diffusion model trained from scratch under the pre-training and supervised fine-tuning (SFT) paradigm. LLaDA employs a forward data masking process and a reverse generation process, parameterized by a Transformer to predict masked tokens. It provides a principled generative approach for probabilistic inference by optimizing a likelihood lower bound. Across extensive benchmarks on general tasks, math, code, and so on, LLaDA demonstrates strong *scalability* and performs comparably to our self-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong LLMs like LLaMA3 8B in *in-context learning* and, after SFT, exhibits impressive *instruction-following* abilities in case studies such as multi-turn dialogue. Moreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal poem completion task. Our findings show the promise of diffusion models for language modeling at scale and challenge the common assumption that core LLM capabilities discussed above inherently depend on ARMs. Project page and codes: \\url{https://ml-gsai.github.io/LLaDA-demo/}.",
        "decision": "Accept (oral)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "JRVZTACwb0": {
        "venue": "ICLR 2025",
        "title": "Fast Monte Carlo Tree Diffusion: 100\u00d7 Speedup via Parallel and Sparse Planning",
        "link": "https://openreview.net/forum?id=JRVZTACwb0",
        "abstract": "Diffusion models have recently emerged as a powerful approach for trajectory planning. However, their inherently non-sequential nature limits their effectiveness in long-horizon reasoning tasks at test time. The recently proposed Monte Carlo Tree Diffusion (MCTD) offers a promising solution by combining diffusion with tree-based search, achieving state-of-the-art performance on complex planning problems. Despite its strengths, our analysis shows that MCTD incurs substantial computational overhead due to the sequential nature of tree search and the cost of iterative denoising. To address this, we propose Fast-MCTD, a more efficient variant that preserves the strengths of MCTD while significantly improving its speed and scalability. Fast-MCTD integrates two techniques: Parallel MCTD, which enables parallel rollouts via delayed tree updates and redundancy-aware selection; and Sparse MCTD, which reduces rollout length through trajectory coarsening. Experiments show that Fast-MCTD achieves up to 100\u00d7 speedup over standard MCTD while maintaining or improving planning performance. Remarkably, it even outperforms Diffuser in inference speed on some tasks, despite Diffuser requiring no search and yielding weaker solutions. These results position Fast-MCTD as a practical and scalable solution for diffusion-based inference-time reasoning.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "FjByDpDVIO": {
        "venue": "ICLR 2025",
        "title": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models",
        "link": "https://openreview.net/forum?id=FjByDpDVIO",
        "abstract": "We present Audio Flamingo 3 (AF3), a fully open state-of-the-art (SOTA) large audio-language model that advances reasoning and understanding across speech, sound, and music. AF3 introduces: (i) AF-Whisper, a unified audio encoder trained using a novel strategy for joint representation learning across all 3 modalities of speech, sound, and music; (ii) flexible, on-demand thinking, allowing the model to do chain-of-thought-type reasoning before answering; (iii) multi-turn, multi-audio chat; (iv) long audio understanding and reasoning (including speech) up to 10 minutes; and (v) voice-to-voice interaction. To enable these capabilities, we propose several large-scale training datasets curated using novel strategies, including AudioSkills-XL, LongAudio-XL, AF-Think, and AF-Chat, and train AF3 with a novel five-stage curriculum-based training strategy. Trained on only open-source audio data, AF3 achieves new SOTA results on over 20+ (long) audio understanding and reasoning benchmarks, surpassing both open-weight and closed-source models trained on much larger datasets.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "E7knuYAvpt": {
        "venue": "ICLR 2025",
        "title": "The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination",
        "link": "https://openreview.net/forum?id=E7knuYAvpt",
        "abstract": "Inspired by recent work on learning with distribution shift, we give a\ngeneral outlier removal algorithm called *iterative polynomial\nfiltering* and show a number of striking applications for supervised\nlearning with contamination:\n(1) We show that any function class that can be approximated by\nlow-degree polynomials with respect to a hypercontractive distribution\ncan be efficiently learned under bounded contamination (also\nknown as *nasty noise*).  This is a surprising resolution to a\nlongstanding gap between the complexity of agnostic learning and\nlearning with contamination, as it was widely believed that low-degree\napproximators only implied tolerance to label noise.\n(2) For any function class that admits the (stronger) notion of\nsandwiching approximators, we obtain near-optimal learning guarantees\neven with respect to heavy additive contamination, where far more than\n$1/2$ of the training set may be added adversarially. Prior\nrelated work held only for regression and in a list-decodable setting.\n(3) We obtain the first efficient algorithms for tolerant testable\nlearning of functions of halfspaces with respect to any fixed\nlog-concave distribution.  Even the non-tolerant case for a single\nhalfspace in this setting had remained open.\nThese results significantly advance our understanding of efficient\nsupervised learning under contamination, a setting that has been much\nless studied than its unsupervised counterpart.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "ATewcZPbDj": {
        "venue": "ICLR 2025",
        "title": "Accelerating 3D Molecule Generative Models with Trajectory Diagnosis",
        "link": "https://openreview.net/forum?id=ATewcZPbDj",
        "abstract": "Geometric molecule generative models have found expanding applications across various scientific domains, but their generation inefficiency has become a critical bottleneck. Through a systematic investigation of the generative trajectory, we discover a unique challenge for molecule geometric graph generation: generative models require determining the permutation order of atoms in the molecule before refining its atomic feature values. Based on this insight, we decompose the generation process into permutation phase and adjustment phase, and propose a geometric-informed prior and consistency parameter objective to accelerate each phase. Extensive experiments demonstrate that our approach achieves competitive performance with approximately 10 sampling steps, 7.5 \u00d7 faster than previous state-of-the-art models and approximately 100 \u00d7 faster than diffusion-based models, offering a significant step towards scalable molecular generation.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "7yRwAEWxto": {
        "venue": "ICLR 2025",
        "title": "InstructSAM: A Training-free Framework for Instruction-Oriented Remote Sensing Object Recognition",
        "link": "https://openreview.net/forum?id=7yRwAEWxto",
        "abstract": "Language-guided object recognition in remote sensing imagery is crucial for large-scale mapping and automated data annotation. However, existing open-vocabulary and visual grounding methods rely on explicit category cues, limiting their ability to handle complex or implicit queries that require advanced reasoning.\nTo address this issue, we introduce a new suite of tasks, including Instruction-Oriented Object Counting, Detection, and Segmentation (InstructCDS), covering open-vocabulary, open-ended, and open-subclass scenarios. We further present EarthInstruct, the first InstructCDS benchmark for earth observation. It is constructed from two diverse remote sensing datasets with varying spatial resolutions and annotation rules across 20 categories, necessitating models to interpret dataset-specific instructions.\nGiven the scarcity of semantically rich labeled data in remote sensing, we propose InstructSAM, a training-free framework for instruction-driven object recognition. InstructSAM leverages large vision-language models to interpret user instructions and estimate object counts, employs SAM2 for mask proposal, and formulates mask-label assignment as a binary integer programming problem. By integrating semantic similarity with counting constraints, InstructSAM efficiently assigns categories to predicted masks without relying on confidence thresholds. Experiments demonstrate that InstructSAM matches or surpasses specialized baselines across multiple tasks while maintaining near-constant inference time regardless of object count, reducing output tokens by 89\\% and overall runtime by over 32\\% compared to direct generation approaches. We believe the contributions of the proposed tasks, benchmark, and effective approach will advance future research in developing versatile object recognition systems. The code is available at https://VoyagerXvoyagerx.github.io/InstructSAM.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "74SvE2GZwW": {
        "venue": "ICLR 2025",
        "title": "Deep Continuous-Time State-Space Models for Marked Event Sequences",
        "link": "https://openreview.net/forum?id=74SvE2GZwW",
        "abstract": "Marked temporal point processes (MTPPs) model sequences of events occurring at irregular time intervals, with wide-ranging applications in fields such as healthcare, finance and social networks. We propose the _state-space point process_ (S2P2) model, a novel and performant model that leverages techniques derived for modern deep state-space models (SSMs) to overcome limitations of existing MTPP models, while simultaneously imbuing strong inductive biases for continuous-time event sequences that other discrete sequence models (i.e., RNNs, transformers) do not capture. Inspired by the classical linear Hawkes processes, we propose an architecture that interleaves stochastic jump differential equations with nonlinearities to create a highly expressive intensity-based MTPP model, without the need for restrictive parametric assumptions for the intensity. Our approach enables efficient training and inference with a parallel scan, bringing linear complexity and sublinear scaling while retaining expressivity to MTPPs. Empirically, S2P2 achieves state-of-the-art predictive likelihoods across eight real-world datasets, delivering an average improvement of 33% over the best existing approaches.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "6iRZvJiC9Q": {
        "venue": "ICLR 2025",
        "title": "OpenCUA: Open Foundations for Computer-Use Agents",
        "link": "https://openreview.net/forum?id=6iRZvJiC9Q",
        "abstract": "Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state\u2013action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-72B achieves an average success rate of 45.0% on OSWorld\u2011Verified, establishing a new state-of-the-art (SOTA) among open-source models. Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "5X6PL4906S": {
        "venue": "ICLR 2025",
        "title": "The Generative Leap: Tight Sample Complexity for Efficiently Learning Gaussian Multi-Index Models",
        "link": "https://openreview.net/forum?id=5X6PL4906S",
        "abstract": "In this work we consider generic Gaussian Multi-index models, in which the labels only depend on the (Gaussian) $d$-dimensional inputs through their projection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient agnostic estimation procedures for this hidden subspace. We introduce the *generative leap* exponent, a natural extension of the generative exponent from Damian et al. 2024 to the multi-index setting. We show that a sample complexity of $n=\\Theta(d^{1 \\vee k^\\star/2})$ is necessary in the class of algorithms captured by the Low-Degree-Polynomial framework; and also sufficient, by giving a sequential estimation procedure based on a spectral U-statistic over appropriate Hermite tensors.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "4GyTBGBVsB": {
        "venue": "ICLR 2025",
        "title": "Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing",
        "link": "https://openreview.net/forum?id=4GyTBGBVsB",
        "abstract": "Large vision-language models (LVLMs) derive their capabilities from extensive training on vast corpora of visual and textual data. \nEmpowered by large-scale parameters, these models often exhibit strong memorization of their training data, rendering them susceptible to membership inference attacks (MIAs).\nExisting MIA methods for LVLMs typically operate under white- or gray-box assumptions, by extracting likelihood-based features for the suspected data samples based on the target LVLMs. \nHowever, mainstream LVLMs generally only expose generated outputs while concealing internal computational features during inference, limiting the applicability of these methods.\nIn this work, we propose the first black-box MIA framework for LVLMs, based on a prior knowledge-calibrated memory probing mechanism. \nThe core idea is to assess the model memorization of the private semantic information embedded within the suspected image data, which is unlikely to be inferred from general world knowledge alone.\nWe conducted extensive experiments across four LVLMs and three datasets.\nEmpirical results demonstrate that our method effectively identifies training data of LVLMs in a purely black-box setting and even achieves performance comparable to gray-box and white-box methods.\nFurther analysis reveals the robustness of our method against potential adversarial manipulations, and the effectiveness of the methodology designs.\nOur code and data are available at \\url{https://github.com/spmede/KCMP}.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "3YguS2rxdk": {
        "venue": "ICLR 2025",
        "title": "STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis",
        "link": "https://openreview.net/forum?id=3YguS2rxdk",
        "abstract": "We present STARFlow, a scalable generative model based on normalizing flows that achieves strong performance on high-resolution image synthesis. \nSTARFlow's main building block is Transformer Autoregressive Flow (TARFlow), which combines normalizing flows with Autoregressive Transformer architectures and has recently achieved impressive results in image modeling. In this work, we first establish the theoretical universality of TARFlow for modeling continuous distributions. Building on this foundation, we introduce a set of architectural and algorithmic innovations that significantly enhance the scalability: (1) a deep-shallow design where a deep Transformer block captures most of the model\u2019s capacity, followed by a few shallow Transformer blocks that are computationally cheap yet contribute non-negligibly, (2) learning in the latent space of pretrained autoencoders, which proves far more effective than modeling pixels directly, and (3) a novel guidance algorithm that substantially improves sample quality. Crucially, our model remains a single, end-to-end normalizing flow, allowing exact maximum likelihood training in continuous space without discretization. STARFlow achieves competitive results in both class- and text-conditional image generation, with sample quality approaching that of state-of-the-art diffusion models. To our knowledge, this is the **first** successful demonstration of normalizing flows at this scale and resolution. Code and weights available at https://github.com/apple/ml-starflow.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "1b7whO4SfY": {
        "venue": "ICLR 2025",
        "title": "Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free",
        "link": "https://openreview.net/forum?id=1b7whO4SfY",
        "abstract": "Gating mechanisms have been widely utilized, from early models like LSTMs and Highway Networks to recent state space models, linear attention, and also softmax attention.\nYet, existing literature rarely examines the specific effects of gating.\nIn this work, we conduct comprehensive experiments to systematically investigate gating-augmented softmax attention variants.\nSpecifically, we perform a comprehensive comparison over 30 variants of 15B Mixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion token dataset.\nOur central finding is that a simple modification\u2014applying a head-specific sigmoid gate after the Scaled Dot-Product Attention (SDPA)\u2014consistently improves performance.\nThis modification also enhances training stability, tolerates larger learning rates, and improves scaling properties.\nBy comparing various gating positions and computational variants, we attribute this effectiveness to two key factors: (1) introducing non-linearity upon the low-rank mapping in the softmax attention, and (2) applying query-dependent sparse gating scores to modulate the SDPA output.\nNotably, we find this sparse gating mechanism mitigates `massive activation`, `attention sink` and enhances long-context extrapolation performance. \nWe also release related codes (https://github.com/qiuzh20/gated_attention}) and models (https://huggingface.co/QwQZh/gated_attention) to facilitate future research.\nFurthermore, the most effective SDPA output gating is used in the Qwen3-Next models (https://huggingface.co/collections/Qwen/qwen3-next).",
        "decision": "Accept (oral)",
        "review scores": [
            6,
            4,
            6,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "kE4XEY7Bbc": {
        "venue": "ICLR 2025",
        "title": "Model\u2013Behavior Alignment under Flexible Evaluation: When the Best-Fitting Model Isn\u2019t the Right One",
        "link": "https://openreview.net/forum?id=kE4XEY7Bbc",
        "abstract": "Linearly transforming stimulus representations of deep neural networks yields\nhigh-performing models of behavioral and neural responses to complex stimuli.\nBut does the test accuracy of such predictions identify genuine representational\nalignment? We addressed this question through a large-scale model-recovery study.\nTwenty diverse vision models were linearly aligned to 4.5 million behavioral judg-\nments from the THINGS odd-one-out dataset and calibrated to reproduce human\nresponse variability. For each model in turn, we sampled synthetic responses\nfrom its probabilistic predictions, fitted all candidate models to the synthetic data,\nand tested whether the data-generating model would re-emerge as the best predictor of the simulated data. Model recovery accuracy improved with training-set\nsize but plateaued below 80%, even at millions of simulated trials. Regression\nanalyses linked misidentification primarily to shifts in representational geometry\ninduced by the linear transformation, as well as to the effective dimensionality\nof the transformed features. These findings demonstrate that, even with massive\nbehavioral data, overly flexible alignment metrics may fail to guide us toward artificial representations that are genuinely more human-aligned. Model comparison\nexperiments must be designed to balance the trade-off between predictive accuracy\nand identifiability\u2014ensuring that the best-fitting model is also the right one.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            6,
            5,
            4,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "V7m2oQ5OFW": {
        "venue": "ICLR 2025",
        "title": "On the Universal Near Optimality of Hedge in Combinatorial Settings",
        "link": "https://openreview.net/forum?id=V7m2oQ5OFW",
        "abstract": "In this paper, we study the classical Hedge algorithm in combinatorial settings. In each round, the learner selects a vector $\\mathbf{x}_t$ from a set $\\mathcal{X} \\subseteq$ {$0,1$}$^d$, observes a full loss vector $\\mathbf{y}_t \\in \\mathbb{R}^d$, and incurs a loss $\\langle \\mathbf{x}_t, \\mathbf{y}_t \\rangle \\in [-1,1]$. This setting captures several important problems, including extensive-form games, resource allocation, $m$-sets, online multitask learning, and shortest-path problems on directed acyclic graphs (DAGs). It is well known that Hedge achieves a regret of $\\mathcal{O}\\big(\\sqrt{T \\log |\\mathcal{X}|}\\big)$ after $T$ rounds of interaction. In this paper, we ask whether Hedge is optimal across all combinatorial settings. To that end, we show that for any $\\mathcal{X} \\subseteq$ {$0,1$}$^d$, Hedge is near-optimal\u2014specifically, up to a $\\sqrt{\\log d}$ factor\u2014by establishing a lower bound of $\\Omega\\big(\\sqrt{T \\log(|\\mathcal{X}|)/\\log d}\\big)$ that holds for any algorithm. We then identify a natural class of combinatorial sets\u2014namely, $m$-sets with $\\log d \\leq m \\leq \\sqrt{d}$\u2014for which this lower bound is tight, and for which Hedge is provably suboptimal by a factor of exactly $\\sqrt{\\log d}$. At the same time, we show that Hedge is optimal for online multitask learning, a generalization of the classical $K$-experts problem. Finally, we leverage the near-optimality of Hedge to establish the existence of a near-optimal regularizer for online shortest-path problems in DAGs\u2014a setting that subsumes a broad range of combinatorial domains. Specifically, we show that the classical Online Mirror Descent (OMD) algorithm, when instantiated with the dilated entropy regularizer, is iterate-equivalent to Hedge, and therefore inherits its near-optimal regret guarantees for DAGs.",
        "decision": "Accept (spotlight)",
        "review scores": [
            6,
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "NM4emKloy6": {
        "venue": "ICLR 2025",
        "title": "Learning (Approximately) Equivariant Networks via Constrained Optimization",
        "link": "https://openreview.net/forum?id=NM4emKloy6",
        "abstract": "Equivariant neural networks are designed to respect symmetries through their architecture, boosting generalization and sample efficiency when those symmetries are present in the data distribution. Real-world data, however, often departs from perfect symmetry because of noise, structural variation, measurement bias, or other symmetry-breaking effects. Strictly equivariant models may struggle to fit the data, while unconstrained models lack a principled way to leverage partial symmetries. Even when the data is fully symmetric, enforcing equivariance can hurt training by limiting the model to a restricted region of the parameter space. Guided by homotopy principles, where an optimization problem is solved by gradually transforming a simpler problem into a complex one, we introduce Adaptive Constrained Equivariance (ACE), a constrained optimization approach that starts with a flexible, non-equivariant model and gradually reduces its deviation from equivariance. This gradual tightening smooths training early on and settles the model at a data-driven equilibrium, balancing between equivariance and non-equivariance. Across multiple architectures and tasks, our method consistently improves performance metrics, sample efficiency, and robustness to input perturbations compared with strictly equivariant models and heuristic equivariance relaxations.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            6,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "zzUXS4f91r": {
        "venue": "ICLR 2025",
        "title": "DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization",
        "link": "https://openreview.net/forum?id=zzUXS4f91r",
        "abstract": "The recent success and openness of DeepSeek-R1 have brought widespread attention to Group Relative Policy Optimization (GRPO) as a reinforcement learning method for large reasoning models (LRMs). In this work, we analyze the GRPO objective under a binary reward setting and reveal an inherent limitation of question-level difficulty bias arising from its group relative advantage function. We also identify a connection between GRPO and traditional discriminative methods in supervised learning. Motivated by these insights, we introduce a new **Discriminative Constrained Optimization (DisCO)** framework for reinforcing LRMs, grounded in the principle of discriminative learning: increasing the scores of positive answers while decreasing those of negative ones. The main differences between DisCO and GRPO and its recent variants are: (1) it replaces the group relative objective with a discriminative objective defined by a scoring function; (2) it abandons clipping-based surrogates in favor of non-clipping RL surrogate objectives used as scoring functions; (3) it employs a simple yet effective constrained optimization approach to enforce the KL divergence constraint.  As a result, DisCO offers notable advantages over GRPO and its variants: (i)  it completely eliminates difficulty bias by adopting discriminative objectives; (ii) it addresses the entropy instability in GRPO and its variants through the use of non-clipping scoring functions and a constrained optimization approach, yielding long and stable training dynamics; (iii) it allows the incorporation of advanced discriminative learning techniques to address data imbalance, where a significant number of questions have more negative than positive generated answers during training. Our experiments on enhancing the mathematical reasoning capabilities of SFT-finetuned models show that DisCO significantly outperforms GRPO and its improved variants such as DAPO, achieving average gains of 7\\% over GRPO and 6\\% over DAPO across six benchmark tasks for a 1.5B model.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "zwCb9cKHpd": {
        "venue": "ICLR 2025",
        "title": "SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing",
        "link": "https://openreview.net/forum?id=zwCb9cKHpd",
        "abstract": "3D spatial reasoning in dynamic, audio-visual environments is a cornerstone of human cognition yet remains largely unexplored by existing Audio-Visual Large Language Models (AV-LLMs) and benchmarks, which predominantly focus on static or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D spatial reasoning in dynamic scenes with synchronized spatial audio. SAVVY-Bench is comprised of thousands of carefully curated question\u2013answer pairs probing both directional and distance relationships involving static and moving objects, and requires fine-grained temporal grounding, consistent 3D localization, and multi-modal annotation. To tackle this challenge, we propose SAVVY, a novel training-free reasoning pipeline that consists of two stages: (i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as other audio-visual methods to track the trajectories of key objects related to the query using both visual and spatial audio cues, and (ii) Dynamic Global Map Construction, which aggregates multi-modal queried object trajectories and converts them into a unified global dynamic map. Using the constructed map, a final QA answer is obtained through a coordinate transformation that aligns the global map with the queried viewpoint. Empirical evaluation demonstrates that SAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a new standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "zprMrpiLgT": {
        "venue": "ICLR 2025",
        "title": "CURE: Concept Unlearning via Orthogonal Representation Editing in Diffusion Models",
        "link": "https://openreview.net/forum?id=zprMrpiLgT",
        "abstract": "As Text-to-Image models continue to evolve, so does the risk of generating unsafe, copyrighted, or privacy-violating content. Existing safety interventions - ranging from training data curation and model fine-tuning to inference-time filtering and guidance - often suffer from incomplete concept removal, susceptibility to jail-breaking, computational inefficiency, or collateral damage to unrelated capabilities. In this paper, we introduce CURE, a training-free concept unlearning framework that operates directly in the weight space of pre-trained diffusion models, enabling fast, interpretable, and highly specific suppression of undesired concepts. At the core of our method is the Spectral Eraser, a closed-form, orthogonal projection module that identifies discriminative subspaces using Singular Value Decomposition over token embeddings associated with the concepts to forget and retain. Intuitively, the Spectral Eraser identifies  and isolates features unique to the undesired concept while preserving safe attributes. This operator is then applied in a single step update to yield an edited model in which the target concept is effectively unlearned - without retraining, supervision, or iterative optimization. To balance the trade-off between filtering toxicity and preserving unrelated concepts, we further introduce an Expansion Mechanism for spectral regularization which selectively modulates singular vectors based on their relative significance to control the strength of forgetting. All the processes above are in closed-form, guaranteeing extremely efficient erasure in only $2$ seconds. Benchmarking against prior approaches, CURE achieves a more efficient and thorough removal for targeted artistic styles, objects, identities, or explicit content, with minor damage to original generation ability and demonstrates enhanced robustness against red-teaming. Project Page at \\url{https://sites.google.com/view/cure-unlearning/home}.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "zQK6IluJi3": {
        "venue": "ICLR 2025",
        "title": "Dynamic Masking and Auxiliary Hash Learning for Enhanced Cross-Modal Retrieval",
        "link": "https://openreview.net/forum?id=zQK6IluJi3",
        "abstract": "The demand for multimodal data processing drives the development of information technology. Cross-modal hash retrieval has attracted much attention because it can overcome modal differences and achieve efficient retrieval, and has shown great application potential in many practical scenarios. Existing cross-modal hashing methods have difficulties in fully capturing the semantic information of different modal data, which leads to a significant semantic gap between modalities. Moreover, these methods often ignore the importance differences of channels, and due to the limitation of a single goal, the matching effect between hash codes is also affected to a certain extent, thus facing many challenges. To address these issues, we propose a Dynamic Masking and Auxiliary Hash Learning (AHLR) method for enhanced cross-modal retrieval. By jointly leveraging the dynamic masking and auxiliary hash learning mechanisms, our approach effectively resolves the problems of channel information imbalance and insufficient key information capture, thereby significantly improving the retrieval accuracy. Specifically, we introduce a dynamic masking mechanism that automatically screens and weights the key information in images and texts during the training process, enhancing the accuracy of feature matching. We further construct an auxiliary hash layer to adaptively balance the weights of features across each channel, compensating for the deficiencies of traditional methods in key information capture and channel processing. In addition, we design a contrastive loss function to optimize the generation of hash codes and enhance their discriminative power, further improving the performance of cross-modal retrieval. Comprehensive experimental results on NUS-WIDE, MIRFlickr-25K and MS-COCO benchmark datasets show that the proposed AHLR algorithm outperforms several existing algorithms.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            4,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "zL4ifL17bU": {
        "venue": "ICLR 2025",
        "title": "Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing",
        "link": "https://openreview.net/forum?id=zL4ifL17bU",
        "abstract": "Long-distance depth imaging holds great promise for applications such as autonomous driving and robotics. Direct time-of-flight (dToF) imaging offers high-precision, long-distance depth sensing, yet demands ultra-short pulse light sources and high-resolution time-to-digital converters. In contrast, indirect time-of-flight (iToF) imaging often suffers from phase wrapping and low signal-to-noise ratio (SNR) as the sensing distance increases. In this paper, we introduce a novel ToF imaging paradigm, termed Burst-Encodable Time-of-Flight (BE-ToF), which facilitates high-fidelity, long-distance depth imaging. Specifically, the BE-ToF system emits light pulses in burst mode and estimates the phase delay of the reflected signal over the entire burst period, thereby effectively avoiding the phase wrapping inherent to conventional iToF systems. Moreover, to address the low SNR caused by light attenuation over increasing distances, we propose an end-to-end learnable framework that jointly optimizes the coding functions and the depth reconstruction network. A specialized double well function and first-order difference term are incorporated into the framework to ensure the hardware implementability of the coding functions. The proposed approach is rigorously validated through comprehensive simulations and real-world prototype experiments, demonstrating its effectiveness and practical applicability. The code is available at: https://github.com/ComputationalPerceptionLab/BE-ToF.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "zJdutIT6vT": {
        "venue": "ICLR 2025",
        "title": "Discovering Opinion Intervals from Conflicts in Signed Graphs",
        "link": "https://openreview.net/forum?id=zJdutIT6vT",
        "abstract": "Online social media provide a platform for people to discuss current events and exchange opinions with their peers. While interactions are predominantly positive, in recent years, there has been a lot of research to understand the conflicts in social networks and how they are based on different views and opinions.  In this paper, we ask whether the conflicts in a network reveal a small and interpretable set of prevalent opinion ranges that explain the users' interactions.  More precisely, we consider signed graphs, where the edge signs indicate positive and negative interactions of node pairs, and our goal is to infer opinion intervals that are consistent with the edge signs.  We introduce an optimization problem that models this question, and we give strong hardness results and a polynomial-time approximation scheme by utilizing connections to interval graphs and the Correlation Clustering problem.  We further provide scalable heuristics and show that in experiments they yield more expressive solutions than Correlation Clustering baselines. We also present a case study on a novel real-world dataset from the German parliament, showing that our algorithms can recover the political leaning of German parties based on co-voting behavior.",
        "decision": "Accept (oral)",
        "review scores": [
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "z9oeQrcNh9": {
        "venue": "ICLR 2025",
        "title": "ARM: Adaptive Reasoning Model",
        "link": "https://openreview.net/forum?id=z9oeQrcNh9",
        "abstract": "While large reasoning models demonstrate strong performance on complex tasks, they lack the ability to adjust reasoning token usage based on task difficulty. This often leads to the \"overthinking\" problem\u2014excessive and unnecessary reasoning\u2014which, although potentially mitigated by human intervention to control the token budget, still fundamentally contradicts the goal of achieving fully autonomous AI. In this work, we propose Adaptive Reasoning Model (ARM), a reasoning model capable of adaptively selecting appropriate reasoning formats based on the task at hand. These formats include three efficient ones\u2014Direct Answer, Short CoT, and Code\u2014as well as a more elaborate format, Long CoT. To train ARM, we introduce Ada-GRPO, an adaptation of Group Relative Policy Optimization (GRPO), which addresses the format collapse issue in traditional GRPO. Ada-GRPO enables ARM to achieve high token efficiency, reducing tokens by an average of $\\sim$30%, and up to $\\sim$70%, while maintaining performance comparable to the model that relies solely on Long CoT. Furthermore, not only does it improve inference efficiency through reduced token generation, but it also brings a $\\sim$2$\\times$ speedup in training. In addition to the default Adaptive Mode, ARM supports two additional reasoning modes: 1) Instruction-Guided Mode, which allows users to explicitly specify the reasoning format via special tokens\u2014ideal when the appropriate format is known for a batch of tasks. 2) Consensus-Guided Mode, which aggregates the outputs of the three efficient formats and resorts to Long CoT in case of disagreement, prioritizing performance with higher token usage. All the resources will be released.",
        "decision": "Accept (spotlight)",
        "review scores": [
            4,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "z4AMrCOetn": {
        "venue": "ICLR 2025",
        "title": "LogicTree: Improving Complex Reasoning of LLMs via Instantiated Multi-step Synthetic Logical Data",
        "link": "https://openreview.net/forum?id=z4AMrCOetn",
        "abstract": "Despite their remarkable performance on various tasks, Large Language Models (LLMs) still struggle with logical reasoning, particularly in complex and multi-step reasoning processes. \nAmong various efforts to enhance LLMs' reasoning capabilities, synthesizing large-scale, high-quality logical reasoning datasets has emerged as a promising direction. \nHowever, existing methods often rely on predefined templates for logical reasoning data generation, limiting their adaptability to real-world scenarios. \nTo address the limitation, we propose **LogicTree**, a novel framework for efficiently synthesizing multi-step logical reasoning dataset that excels in both complexity and instantiation.\nBy iteratively searching for applicable logic rules based on structural pattern matching to perform backward deduction, **LogicTree** constructs multi-step logic trees that capture complex reasoning patterns. \nFurthermore, we employ a two-stage LLM-based approach to instantiate various real-world scenarios for each logic tree, generating consistent real-world reasoning processes that carry contextual significance.   This helps LLMs develop generalizable logical reasoning abilities across diverse scenarios rather than merely memorizing templates.\nExperiments on multiple benchmarks demonstrate that our approach achieves an average improvement of 9.4\\% in accuracy on complex logical reasoning tasks.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "z1wIUZtBmK": {
        "venue": "ICLR 2025",
        "title": "COALA: Numerically Stable and Efficient Framework for Context-Aware Low-Rank Approximation",
        "link": "https://openreview.net/forum?id=z1wIUZtBmK",
        "abstract": "Recent studies suggest that context-aware low-rank approximation is a useful tool for compression and fine-tuning of modern large-scale neural networks.\nIn this type of approximation, a norm is weighted by a matrix of input activations, significantly improving metrics over the unweighted case. \nNevertheless, existing methods for neural networks suffer from numerical instabilities due to their reliance on classical formulas involving explicit Gram matrix computation and their subsequent inversion. \nWe demonstrate that this can degrade the approximation quality or cause numerically singular matrices.\n\nTo address these limitations, we propose a novel _inversion-free regularized framework_ that is based entirely on stable decompositions and overcomes the numerical pitfalls of prior art. \nOur method can handle all possible challenging scenarios: (1)&nbsp;when calibration matrices exceed GPU memory capacity, (2)&nbsp;when input activation matrices are nearly singular, and even (3)&nbsp;when insufficient data prevents unique approximation.\nFor the latter, we prove that our solution converges to a desired approximation and derive explicit error bounds.",
        "decision": "Accept (poster)",
        "review scores": [
            4,
            6,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "yzl5tL0Z2M": {
        "venue": "ICLR 2025",
        "title": "Semantic Representation Attack against Aligned Large Language Models",
        "link": "https://openreview.net/forum?id=yzl5tL0Z2M",
        "abstract": "Large Language Models (LLMs) increasingly employ alignment techniques to prevent harmful outputs. Despite these safeguards, attackers can circumvent them by crafting prompts that induce LLMs to generate harmful content. Current methods typically target exact affirmative responses, suffering from limited convergence, unnatural prompts, and high computational costs. We introduce semantic representation attacks, a novel paradigm that fundamentally reconceptualizes adversarial objectives against aligned LLMs. Rather than targeting exact textual patterns, our approach exploits the semantic representation space that can elicit diverse responses that share equivalent harmful meanings. This innovation resolves the inherent trade-off between attack effectiveness and prompt naturalness that plagues existing methods. Our Semantic Representation Heuristic Search (SRHS) algorithm efficiently generates semantically coherent adversarial prompts by maintaining interpretability during incremental search. We establish rigorous theoretical guarantees for semantic convergence and demonstrate that SRHS achieves unprecedented attack success rates (89.4% averaged across 18 LLMs, including 100% on 11 models) while significantly reducing computational requirements. Extensive experiments show that our method consistently outperforms existing approaches.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "yRxXTdElLv": {
        "venue": "ICLR 2025",
        "title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications",
        "link": "https://openreview.net/forum?id=yRxXTdElLv",
        "abstract": "Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging on SQL issues. In order to address this gap, we introduce **BIRD-CRITIC**, a new SQL issue debugging benchmark comprising 530 carefully curated PostgreSQL tasks (**BIRD-CRITIC-PG**) and 570 multi-dialect tasks (**BIRD-CRITIC-Multi**), which are distilled from authentic user issues and replayed within new environments to facilitate rigorous and contamination-free evaluation. Baseline evaluations on BIRD-CRITIC underscore the task's complexity, with the leading reasoning model **O3-Mini** achieving only 38.87% success rate on **BIRD-CRITIC-PG** and 33.33% on **BIRD-CRITIC-Multi**. Meanwhile, realizing open-source models for database tasks is crucial which can empower local development while safeguarding data privacy. Therefore, we present **Six-Gym** (**S**ql-f**IX**-Gym), a training environment for elevating the capabilities of open-source models specifically for SQL issue debugging. This environment leverages **SQL-Rewind** strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose *f*-Plan Boosting, which extracts high-level debugging plans automatically from SQL solutions, enabling the teacher LLMs to harvest and produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, **BIRD-Fixer**. Based on Qwen-2.5-Coder-14B, **BIRD-Fixer** raises its success rate to 38.11% on **BIRD-CRITIC-PG** and 29.65% on **BIRD-CRITIC-Multi**, surpassing many leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities for both research and industry.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "yPnEvPq3kV": {
        "venue": "ICLR 2025",
        "title": "Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components",
        "link": "https://openreview.net/forum?id=yPnEvPq3kV",
        "abstract": "We introduce a novel framework for decomposing interventional causal effects into synergistic, redundant, and unique components, building on the intuition of Partial Information Decomposition (PID) and the principle of M\u00f6bius inversion. While recent work has explored a similar decomposition of an observational measure, we argue that a proper causal decomposition must be interventional in nature. We develop a mathematical approach that systematically quantifies how causal power is distributed among variables in a system, using a recently derived closed-form expression for the M\u00f6bius function of the redundancy lattice. The formalism is then illustrated by decomposing the causal power in logic gates, cellular automata, and chemical reaction networks. Our results reveal how the distribution of causal power can be context- and parameter-dependent. The decomposition provides new insights into complex systems by revealing how causal influences are shared and combined among multiple variables, with potential applications ranging from attribution of responsibility in legal or AI systems, to the analysis of biological networks or climate models.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "yMXn86pzWx": {
        "venue": "ICLR 2025",
        "title": "Visual Jenga: Discovering Object Dependencies via Counterfactual Inpainting",
        "link": "https://openreview.net/forum?id=yMXn86pzWx",
        "abstract": "This paper proposes a novel scene understanding task called Visual Jenga. Drawing inspiration from the game Jenga, the proposed task involves progressively removing objects from a single image until only the background remains. Just as Jenga players must understand structural dependencies to maintain tower stability, our task reveals the intrinsic relationships between scene elements by systematically exploring which objects can be removed while preserving scene coherence in both physical and geometric sense. As a starting point for tackling the Visual Jenga task, we propose a simple, data-driven, training-free approach that is surprisingly effective on a range of real-world images. The principle behind our approach is to utilize the asymmetry in the pairwise relationships between objects within a scene and employ a large inpainting model to generate a set of counterfactuals to quantify the asymmetry.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "yEddfz9SgJ": {
        "venue": "ICLR 2025",
        "title": "Enhancing Infrared Vision: Progressive Prompt Fusion Network and Benchmark",
        "link": "https://openreview.net/forum?id=yEddfz9SgJ",
        "abstract": "We engage in the relatively underexplored task named thermal infrared image enhancement. Existing infrared image enhancement methods primarily focus on tackling individual degradations, such as noise, contrast, and blurring, making it difficult to handle coupled degradations. Meanwhile, all-in-one enhancement methods, commonly applied to RGB sensors, often demonstrate limited effectiveness due to the significant differences in imaging models. In sight of this, we first revisit the imaging mechanism and introduce a Recurrent Prompt Fusion Network (RPFN). Specifically, the RPFN initially establishes prompt pairs based on the thermal imaging process. For each type of degradation, we fuse the corresponding prompt pairs to modulate the model's features, providing adaptive guidance that enables the model to better address specific degradations under single or multiple conditions.In addition, a selective recurrent training mechanism is introduced to gradually refine the model's handling of composite cases to align the enhancement process, which not only allows the model to remove camera noise and retain key structural details, but also enhancing the overall contrast of the thermal image. Furthermore, we introduce the most comprehensive high-quality infrared benchmark covering a wide range of scenarios. Extensive experiments substantiate that our approach not only delivers promising visual results under specific degradation but also significantly improves performance on complex degradation scenes, achieving a notable 8.76% improvement.",
        "decision": "Accept (poster)",
        "review scores": [
            4,
            5,
            5,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "y8VWYf5cVI": {
        "venue": "ICLR 2025",
        "title": "Differentiable Hierarchical Visual Tokenization",
        "link": "https://openreview.net/forum?id=y8VWYf5cVI",
        "abstract": "Vision Transformers rely on fixed patch tokens that ignore the spatial and semantic structure of images. In this work, we introduce an end-to-end differentiable tokenizer that adapts to image content with pixel-level granularity while remaining backward-compatible with existing architectures for retrofitting pretrained models. Our method uses hierarchical model selection with information criteria to provide competitive performance in both image-level classification and dense-prediction tasks, and even supports out-of-the-box raster-to-vector conversion.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "y7ahj9RoXQ": {
        "venue": "ICLR 2025",
        "title": "ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints",
        "link": "https://openreview.net/forum?id=y7ahj9RoXQ",
        "abstract": "Spatial reasoning is a key capability in the field of artificial intelligence, especially crucial in areas such as robotics, computer vision, and natural language understanding. However, evaluating the ability of multimodal large language models (MLLMs) in complex spatial reasoning still faces challenges, particularly in scenarios requiring multi-step reasoning and precise mathematical constraints. This paper introduces ORIGAMISPACE, a new dataset and benchmark designed to evaluate the multi-step spatial reasoning ability and the capacity to handle mathematical constraints of MLLMs through origami tasks. The dataset contains 350 data instances, each comprising a strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the complete Folding Process, and the final Folded Shape Image. We propose four evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial Relationship Prediction, and End-to-End CP Code Generation. For the CP code generation task, we design an interactive environment and explore the possibility of using reinforcement learning methods to train MLLMs. Through experiments on existing MLLMs, we initially reveal the strengths and weaknesses of these models in handling complex spatial reasoning tasks.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "y0wDflmpLk": {
        "venue": "ICLR 2025",
        "title": "Continuous Thought Machines",
        "link": "https://openreview.net/forum?id=y0wDflmpLk",
        "abstract": "Biological brains demonstrate complex neural activity, where neural dynamics are critical to how brains process information. Most artificial neural networks ignore the complexity of individual neurons. We challenge that paradigm. By incorporating neuron-level processing and synchronization, we reintroduce neural timing as a foundational element. We present the Continuous Thought Machine (CTM), a model designed to leverage neural dynamics as its core representation. The CTM has two innovations: (1) neuron-level temporal processing}, where each neuron uses unique weight parameters to process incoming histories; and (2) neural synchronization as a latent representation. The CTM aims to strike a balance between neuron abstractions and biological realism. It operates at a level of abstraction that effectively captures essential temporal dynamics while remaining computationally tractable. We demonstrate the CTM's performance and versatility across a range of tasks, including solving 2D mazes, ImageNet-1K classification, parity computation, and more. Beyond displaying rich internal representations and offering a natural avenue for interpretation owing to its internal process, the CTM is able to perform tasks that require complex sequential reasoning. The CTM can also leverage adaptive compute, where it can stop earlier for simpler tasks, or keep computing when faced with more challenging instances. The goal of this work is to share the CTM and its associated innovations, rather than pushing for new state-of-the-art results. To that end, we believe the CTM represents a significant step toward developing more biologically plausible and powerful artificial intelligence systems. We provide an accompanying [interactive online demonstration](https://pub.sakana.ai/ctm/) and an [extended technical report](https://pub.sakana.ai/ctm/paper).",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xs5aoDH3HX": {
        "venue": "ICLR 2025",
        "title": "Equi-mRNA: Protein Translation Equivariant Encoding for mRNA Language Models",
        "link": "https://openreview.net/forum?id=xs5aoDH3HX",
        "abstract": "The growing importance of mRNA therapeutics and synthetic biology highlights the need for models that capture the latent structure of synonymous codon (different triplets encoding the same amino acid) usage, which subtly modulates translation efficiency and gene expression. While recent efforts incorporate codon-level inductive biases through auxiliary objectives, they often fall short of explicitly modeling the structured relationships that arise from the genetic code\u2019s inherent symmetries. We introduce Equi\u2011mRNA, the first codon\u2011level equivariant mRNA language model that explicitly encodes synonymous codon symmetries as cyclic subgroups of 2D Special Orthogonal matrix ($\\mathrm{SO}(2)$). By combining group\u2011theoretic priors with an auxiliary equivariance loss and symmetry\u2011aware pooling, Equi\u2011mRNA learns biologically grounded representations that outperform vanilla baselines across multiple axes. On downstream property\u2011prediction tasks including expression, stability, and riboswitch switching Equi\u2011mRNA delivers up to $\\approx$ 10\\% improvements in accuracy. In sequence generation, it produces mRNA constructs that are up to $\\approx$ 4$\\times$ more realistic under Fr\u00e9chet BioDistance metrics and $\\approx$ 28\\% better preserve functional properties compared to vanilla baseline. Interpretability analyses further reveal that learned codon\u2011rotation distributions recapitulate known GC\u2011content biases and tRNA abundance patterns, offering novel insights into codon usage. Equi\u2011mRNA establishes a new biologically principled paradigm for mRNA modeling, with significant implications for the design of next\u2011generation therapeutics.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xlDmm4r98R": {
        "venue": "ICLR 2025",
        "title": "FACT: Mitigating Inconsistent Hallucinations in LLMs via Fact-Driven Alternating Code-Text Training",
        "link": "https://openreview.net/forum?id=xlDmm4r98R",
        "abstract": "Inconsistent hallucinations remain a major challenge for large language models (LLMs), undermining the accuracy and reliability of fact-based reasoning in real-world applications. Existing approaches often rely on task-specific training or adaptation, such as hand-crafted synthetic datasets for domain tasks or solutions mainly focused on numerical reasoning, thereby limiting generalizability to broader, unseen NLP tasks. Inspired by the structural rigor and logical consistency of programming languages, we observe that fact-based texts can be mapped to programming structures due to their inherent patterns. We further propose FACT, a novel Fact-driven Alternating Code-text Training framework that alternates between text-to-code and code-to-text prediction. FACT is the first task-agnostic paradigm that embeds code and natural language in a shared semantic space, thereby transferring the logical consistency of code to LLM outputs in NLP tasks. Experiments show that with only a small subset of Wiki-40B-en for training, FACT reduces inconsistent hallucinations by 2.7%\u20138.0% and improves overall performance by 2.5%\u20136.1% in three leading LLMs and four diverse datasets covering QA and summarization tasks. This framework offers a new perspective on addressing challenging hallucinations in LLMs, contributing to more reliable AI.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            6,
            4
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xgTxQe3CNl": {
        "venue": "ICLR 2025",
        "title": "Improving Evolutionary Multi-View Classification via Eliminating Individual Fitness Bias",
        "link": "https://openreview.net/forum?id=xgTxQe3CNl",
        "abstract": "Evolutionary multi-view classification (EMVC) methods have gained wide recognition due to their adaptive mechanisms. Fitness evaluation (FE), which aims to calculate the classification performance of each individual in the population and provide reliable performance ranking for subsequent operations, is a core step in such methods. Its accuracy directly determines the correctness of the evolutionary direction. That is, when FE fails to correctly reflect the superiority-inferiority relationship among individuals, it will lead to confusion in individual performance ranking, which in turn misleads the evolutionary direction and results in trapping into local optima. This paper is the first to identify the aforementioned issue in the field of EMVC and call it as fitness evaluation bias (FEB). FEB may be caused by a variety of factors, and this paper approaches the issue from the perspective of view information content: existing methods generally adopt joint training strategies, which restrict the exploration of key information in views with low information content. This makes it difficult for multi-view model (MVM) to achieve optimal performance during convergence, which in turn leads to FE failing to accurately reflect individual performance rankings and ultimately triggering FEB. To address this issue, we propose an evolutionary multi-view classification via eliminating individual fitness bias (EFB-EMVC) method, which alleviates the FEB issue by introducing evolutionary navigators for each MVM, thereby providing more accurate individual ranking. Experimental results fully verify the effectiveness of the proposed method in alleviating the FEB problem, and the EMVC method equipped with this strategy exhibits more superior performance compared with the original EMVC method. (The code is available at https://github.com/LiShuailzn/Neurips-2025-EFB-EMVC)",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xdNAVP7TGy": {
        "venue": "ICLR 2025",
        "title": "70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float (DFloat11)",
        "link": "https://openreview.net/forum?id=xdNAVP7TGy",
        "abstract": "Large-scale AI models, such as Large Language Models (LLMs) and Diffusion Models (DMs), have grown rapidly in size, creating significant challenges for efficient deployment on resource-constrained hardware. In this paper, we introduce Dynamic-Length Float (DFloat11), a lossless compression framework that reduces LLM and DM size by 30\\% while preserving outputs that are bit-for-bit identical to the original model. DFloat11 is motivated by the low entropy in the BFloat16 weight representation of LLMs, which reveals significant inefficiency in the existing storage format. By applying entropy coding, DFloat11 assigns dynamic-length encodings to weights based on frequency, achieving near information-optimal compression without any loss of precision. To facilitate efficient inference with dynamic-length encodings, we develop a custom GPU kernel for fast online decompression. Our design incorporates the following: (i) compact, hierarchical lookup tables (LUTs) that fit within GPU SRAM for efficient decoding, (ii) a two-phase GPU kernel for coordinating thread read/write positions using lightweight auxiliary variables, and (iii) transformer-block-level decompression to minimize latency. Experiments on Llama 3.3, Qwen 3, Mistral 3, FLUX.1, and others validate our hypothesis that DFloat11 achieves around 30\\% model size reduction while preserving bit-for-bit identical outputs. Compared to a potential alternative of offloading parts of an uncompressed model to the CPU to meet memory constraints, DFloat11 achieves 2.3--46.2$\\times$ higher throughput in token generation. With a fixed GPU memory budget, DFloat11 enables 5.7--14.9$\\times$ longer generation lengths than uncompressed models. Notably, our method enables lossless inference of Llama 3.1 405B, an 810GB model, on a single node equipped with 8$\\times$80GB GPUs.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xMcKyUGTt1": {
        "venue": "ICLR 2025",
        "title": "Solver-Free Decision-Focused Learning for Linear Optimization Problems",
        "link": "https://openreview.net/forum?id=xMcKyUGTt1",
        "abstract": "Mathematical optimization is a fundamental tool for decision-making in a wide range of applications. However, in many real-world scenarios, the parameters of the optimization problem are not known a priori and must be predicted from contextual features. This gives rise to predict-then-optimize problems, where a machine learning model predicts problem parameters that are then used to make decisions via optimization. A growing body of work on decision-focused learning (DFL) addresses this setting by training models specifically to produce predictions that maximize downstream decision quality, rather than accuracy. While effective, DFL is computationally expensive, because it requires solving the optimization problem with the predicted parameters at each loss evaluation. In this work, we address this computational bottleneck for linear optimization problems, a common class of problems in both DFL literature and real-world applications. We propose a solver-free training method that exploits the geometric structure of linear optimization to enable efficient training with minimal degradation in solution quality. Our method is based on the insight that a solution is optimal if and only if it achieves an objective value that is at least as good as that of its adjacent vertices on the feasible polytope. Building on this, our method compares the estimated quality of the ground-truth optimal solution with that of its precomputed adjacent vertices, and uses this as loss function. Experiments demonstrate that our method significantly reduces computational cost while maintaining high decision quality.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            6,
            4,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xLFYd1owiP": {
        "venue": "ICLR 2025",
        "title": "Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation",
        "link": "https://openreview.net/forum?id=xLFYd1owiP",
        "abstract": "With the rapid advancement of Artificial Intelligence Generated Content (AIGC) technologies, synthetic images have become increasingly prevalent in everyday life, posing new challenges for authenticity assessment and detection. Despite the effectiveness of existing methods in evaluating image authenticity and locating forgeries, these approaches often lack human interpretability and do not fully address the growing complexity of synthetic data. To tackle these challenges, we introduce FakeVLM, a specialized large multimodal model designed for both general synthetic image and DeepFake detection tasks. FakeVLM not only excels in distinguishing real from fake images but also provides clear, natural language explanations for image artifacts, enhancing interpretability. Additionally, we present FakeClue, a comprehensive dataset containing over 100,000 images across seven categories, annotated with fine-grained artifact clues in natural language. FakeVLM demonstrates performance comparable to expert models while eliminating the need for additional classifiers, making it a robust solution for synthetic data detection. Extensive evaluations across multiple datasets confirm the superiority of FakeVLM in both authenticity classification and artifact explanation tasks, setting a new benchmark for synthetic image detection. The code, model weights, and dataset can be found here: https://github.com/opendatalab/FakeVLM.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            4,
            6
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xIH95kXNR2": {
        "venue": "ICLR 2025",
        "title": "MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control",
        "link": "https://openreview.net/forum?id=xIH95kXNR2",
        "abstract": "We study the problem of learning a neural sampler to generate samples from discrete state spaces where the target probability mass function $\\pi\\propto\\mathrm{e}^{-U}$ is known up to a normalizing constant, which is an important task in fields such as statistical physics, machine learning, combinatorial optimization, etc. To better address this challenging task when the state space has a large cardinality and the distribution is multi-modal, we propose **M**asked **D**iffusion **N**eural **S**ampler (**MDNS**), a novel framework for training discrete neural samplers by aligning two path measures through a family of learning objectives, theoretically grounded in the stochastic optimal control of the continuous-time Markov chains. We validate the efficiency and scalability of MDNS through extensive experiments on various distributions with distinct statistical properties, where MDNS learns to accurately sample from the target distributions despite the extremely high problem dimensions and outperforms other learning-based baselines by a large margin. A comprehensive study of ablations and extensions is also provided to demonstrate the efficacy and potential of the proposed framework. Our code is available at https://github.com/yuchen-zhu-zyc/MDNS.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "xDxskDUvte": {
        "venue": "ICLR 2025",
        "title": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness",
        "link": "https://openreview.net/forum?id=xDxskDUvte",
        "abstract": "Adversarial examples reveal critical vulnerabilities in deep neural networks by exploiting their sensitivity to imperceptible input perturbations. While adversarial training remains the predominant defense strategy, it often incurs significant computational cost and may compromise clean-data accuracy. In this work, we investigate an architectural approach to adversarial robustness by embedding group-equivariant convolutions\u2014specifically, rotation- and scale-equivariant layers\u2014into standard convolutional neural networks (CNNs). These layers encode symmetry priors that align model behavior with structured transformations in the input space, promoting smoother decision boundaries and greater resilience to adversarial attacks. We propose and evaluate two symmetry-aware architectures: a parallel design that processes standard and equivariant features independently before fusion, and a cascaded design that applies equivariant operations sequentially. Theoretically, we demonstrate that such models reduce hypothesis space complexity, regularize gradients, and yield tighter certified robustness bounds under the CLEVER (Cross Lipschitz Extreme Value for nEtwork Robustness) framework. Empirically, our models consistently improve adversarial robustness and generalization across CIFAR-10, CIFAR-100, and CIFAR-10C under both FGSM and PGD attacks, without requiring adversarial training. These findings underscore the potential of symmetry-enforcing architectures as efficient and principled alternatives to data augmentation-based defenses.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "wdI2WKCN3P": {
        "venue": "ICLR 2025",
        "title": "HoT-VI: Reparameterizable Variational Inference for Capturing Instance-Level High-Order Correlations",
        "link": "https://openreview.net/forum?id=wdI2WKCN3P",
        "abstract": "Mean-field variational inference (VI), despite its scalability, is limited by the independence assumption, making it unsuitable for scenarios with correlated data instances. Existing structured VI methods either focus on correlations among latent dimensions which lack scalability for modeling instance-level correlations, or are restricted to simple first-order dependencies, limiting their expressiveness. In this paper, we propose High-order Tree-structured Variational Inference (HoT-VI), that explicitly models $k$-order instance-level correlations among latent variables. By expressing the global posterior through overlapping $k$-dimensional local marginals, our method enables efficient parameterized sampling via a sequential procedure. To ensure the validity of these marginals, we introduce a conditional correlation parameterization method that guarantees positive definiteness of their correlation matrices. We further extend our method with a tree-structured backbone to capture more flexible dependency patterns. Extensive experiments on time-series and graph-structured datasets demonstrate that modeling higher-order correlations leads to significantly improved posterior approximations and better performance across various downstream tasks.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "waHF2ekuf2": {
        "venue": "ICLR 2025",
        "title": "Straight-Line Diffusion Model for Efficient 3D Molecular Generation",
        "link": "https://openreview.net/forum?id=waHF2ekuf2",
        "abstract": "Diffusion-based models have shown great promise in molecular generation but often require a large number of sampling steps to generate valid samples. In this paper, we introduce a novel Straight-Line Diffusion Model (SLDM) to tackle this problem, by formulating the diffusion process to follow a linear trajectory. The proposed process aligns well with the noise sensitivity characteristic of molecular structures and uniformly distributes reconstruction effort across the generative process, thus enhancing learning efficiency and efficacy. Consequently, SLDM achieves state-of-the-art performance on 3D molecule generation benchmarks, delivering a 100-fold improvement in sampling efficiency.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "wWSVjaVZBu": {
        "venue": "ICLR 2025",
        "title": "Why Playing Against Diverse and Challenging Opponents Speeds Up Coevolution: A Theoretical Analysis on Combinatorial Games",
        "link": "https://openreview.net/forum?id=wWSVjaVZBu",
        "abstract": "Competitive coevolutionary algorithms (CoEAs) have a natural application to problems that are adversarial or feature strategic interaction. However, there is currently limited theoretical insight into how to avoid pathological behaviour associated with CoEAs. In this paper we use impartial combinatorial games as a challenging domain for CoEAs and provide a corresponding runtime analysis. By analysing how individuals capitalise on the mistakes of their opponents, we prove that the Univariate Marginal Distribution Algorithm finds (with high probability) an optimal strategy for a game called Reciprocal LeadingOnes within $O(n^2\\log^3{n})$ game evaluations, a significant improvement over the best known bound of $O(n^5\\log^2{n})$. Critical to the analysis is the introduction of a novel stabilising operator, the impact of which we study both theoretically and empirically.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "wAq0ZLxrGq": {
        "venue": "ICLR 2025",
        "title": "Tight Generalization Bounds for Large-Margin Halfspaces",
        "link": "https://openreview.net/forum?id=wAq0ZLxrGq",
        "abstract": "We prove the first generalization bound for large-margin halfspaces that is asymptotically tight in the tradeoff between the margin, the fraction of training points with the given margin, the failure probability and the number of training points.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "w4qJ056WhI": {
        "venue": "ICLR 2025",
        "title": "SpaceServe: Spatial Multiplexing of Complementary Encoders and Decoders for Multimodal LLMs",
        "link": "https://openreview.net/forum?id=w4qJ056WhI",
        "abstract": "Recent multimodal large language models (MLLMs) marry modality-specific\nvision or audio encoders with a shared text decoder. While the encoder is compute-\nintensive but memory-light, the decoder is the opposite, yet state-of-the-art serving\nstacks still time-multiplex these complementary kernels, idling SMs or HBM in\nturn. We introduce SpaceServe, a serving system that space-multiplexes MLLMs:\nit decouples all modality encoders from the decoder, and co-locates them on the\nsame GPU using fine-grained SM partitioning available in modern runtimes. A\ncost-model-guided Space-Inference Scheduler (SIS) dynamically assigns SM slices,\nwhile a Time-Windowed Shortest-Remaining-First (TWSRFT) policy batches en-\ncoder requests to minimise completion latency and smooth decoder arrivals. \nEvaluation shows that SpaceServe reduces time-per-output-token by 4.81\u00d7\non average and up to 28.9\u00d7 on Nvidia A100 GPUs. SpaceServe is available at\nhttps://github.com/gofreelee/SpaceServe",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "vATe64ktAo": {
        "venue": "ICLR 2025",
        "title": "Robust Graph Condensation via Classification Complexity Mitigation",
        "link": "https://openreview.net/forum?id=vATe64ktAo",
        "abstract": "Graph condensation (GC) has gained significant attention for its ability to synthesize smaller yet informative graphs. However, existing studies often overlook the robustness of GC in scenarios where the original graph is corrupted. In such cases, we observe that the performance of GC deteriorates significantly, while existing robust graph learning technologies offer only limited effectiveness. Through both empirical investigation and theoretical analysis, we reveal that GC is inherently an intrinsic-dimension-reducing process, synthesizing a condensed graph with lower classification complexity. Although this property is critical for effective GC performance, it remains highly vulnerable to adversarial perturbations. \nTo tackle this vulnerability and improve GC robustness, we adopt the geometry perspective of graph data manifold and propose a novel **M**anifold-constrained **R**obust **G**raph **C**ondensation framework named **MRGC**. Specifically, we introduce three graph data manifold learning modules that guide the condensed graph to lie within a smooth, low-dimensional manifold with minimal class ambiguity, thereby preserving the classification complexity reduction capability of GC and ensuring robust performance under universal adversarial attacks. Extensive experiments demonstrate the robustness of MRGC across diverse attack scenarios.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "v5ru9MGjsW": {
        "venue": "ICLR 2025",
        "title": "Generalization Guarantees for Learning Score-Based Branch-and-Cut Policies in Integer Programming",
        "link": "https://openreview.net/forum?id=v5ru9MGjsW",
        "abstract": "Mixed-integer programming (MIP) provides a powerful framework for optimization problems, with Branch-and-Cut (B&C) being the predominant algorithm in state-of-the-art solvers. The efficiency of B&C critically depends on heuristic policies for making sequential decisions, including node selection, cut selection, and branching variable selection. While traditional solvers often employ heuristics with manually tuned parameters, recent approaches increasingly leverage machine learning, especially neural networks, to learn these policies directly from data. A key challenge is to understand the theoretical underpinnings of these learned policies, particularly their generalization performance from finite data. This paper establishes rigorous sample complexity bounds for learning B&C policies where the scoring functions guiding each decision step (node, cut, branch) have a certain piecewise polynomial structure. This structure generalizes the linear models that form the most commonly deployed policies in practice and investigated recently in a foundational series of theoretical works by Balcan et al. Such piecewise polynomial policies also cover the neural network architectures (e.g., using ReLU activations) that have been the focal point of contemporary practical studies. Consequently, our theoretical framework closely reflects the models utilized by practitioners investigating machine learning within B&C, offering a unifying perspective relevant to both established theory and modern empirical research in this area. Furthermore, our theory applies to quite general sequential decision making problems beyond B&C.",
        "decision": "Accept (poster)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "uwL0vbeEVn": {
        "venue": "ICLR 2025",
        "title": "SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications",
        "link": "https://openreview.net/forum?id=uwL0vbeEVn",
        "abstract": "Speculative decoding is widely adopted to reduce latency in large language model (LLM) inference by leveraging smaller draft models capable of handling diverse user tasks. However, emerging AI applications, such as LLM-based agents, present unique workload characteristics: instead of diverse independent requests, agentic frameworks typically submit repetitive inference requests, such as multi-agent pipelines performing similar subtasks or self-refinement loops iteratively enhancing outputs. These workloads result in long and highly predictable sequences, which current speculative decoding methods do not effectively exploit. To address this gap, we introduce \\emph{SuffixDecoding}, a novel method that utilizes efficient suffix trees to cache long token sequences from prompts and previous outputs. By adaptively speculating more tokens when acceptance likelihood is high and fewer when it is low, SuffixDecoding effectively exploits opportunities for longer speculations while conserving computation when those opportunities are limited. Evaluations on agentic benchmarks, including SWE-Bench and Text-to-SQL, demonstrate that SuffixDecoding achieves speedups of up to 3.9$\\times$, outperforming state-of-the-art methods -- 2.2$\\times$ faster than model-based approaches like EAGLE-2/3 and 1.6$\\times$ faster than model-free approaches such as Token Recycling. SuffixDecoding is open-sourced.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "u1j6RqH8nM": {
        "venue": "ICLR 2025",
        "title": "Scaling Laws For Scalable Oversight",
        "link": "https://openreview.net/forum?id=u1j6RqH8nM",
        "abstract": "Scalable oversight, the process by which weaker AI systems supervise stronger ones, has been proposed as a key strategy to control future superintelligent systems. However, it is still unclear how scalable oversight itself scales.\nTo address this gap, we propose a framework that quantifies the probability of successful oversight as a function of the capabilities of the overseer and the system being overseen.\nSpecifically, our framework models oversight as a game between capability-mismatched players; the players have oversight-specific Elo scores that are a piecewise-linear function of their general intelligence, with two plateaus corresponding to task incompetence and task saturation. We validate our framework with a modified version of the game Nim and then apply it to four oversight games: Mafia,  Debate, Backdoor Code and Wargames. For each game, we find scaling laws that approximate how domain performance depends on general AI system capability. We then build on our findings in a theoretical study of Nested Scalable Oversight (NSO), a process in which trusted models oversee untrusted stronger models, which then become the trusted models in the next step. We identify conditions under which NSO succeeds and derive numerically (and in some cases analytically) the optimal number of oversight levels to maximize the probability of oversight success. We also apply our theory to our four oversight games, where we find that NSO success rates at a general Elo gap of 400 are 13.5\\% for Mafia, 51.7\\% for Debate, 10.0\\% for Backdoor Code, and 9.4\\% for Wargames; these rates decline further when overseeing stronger systems.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "t4aN2G7Ucc": {
        "venue": "ICLR 2025",
        "title": "Dimension-adapted Momentum Outscales SGD",
        "link": "https://openreview.net/forum?id=t4aN2G7Ucc",
        "abstract": "We investigate scaling laws for stochastic momentum algorithms on the power law random features model, parameterized by data complexity, target complexity, and model size. When trained with a stochastic momentum algorithm, our analysis reveals four distinct loss curve shapes determined by varying data-target complexities. While traditional stochastic gradient descent with momentum (SGD-M) yields identical scaling law exponents to SGD, dimension-adapted Nesterov acceleration (DANA) improves these exponents by scaling momentum hyperparameters based on model size and data complexity. This outscaling phenomenon, which also improves compute-optimal scaling behavior, is achieved by DANA across a broad range of data and target complexities, while traditional methods fall short. Extensive experiments on high-dimensional synthetic quadratics validate our theoretical predictions and large-scale text experiments with LSTMs show DANA's improved loss exponents over SGD hold in a practical setting.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    },
    "sm2e1SnMK4": {
        "venue": "ICLR 2025",
        "title": "Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler",
        "link": "https://openreview.net/forum?id=sm2e1SnMK4",
        "abstract": "Harmful fine-tuning poses critical safety risks to fine-tuning-as-a-service for large language models. Existing defense strategies preemptively build robustness via attack simulation but suffer from fundamental limitations: (i) the infeasibility of extending attack simulations beyond bounded threat models due to the inherent difficulty of anticipating unknown attacks, and (ii) limited adaptability to varying attack settings, as simulation fails to capture their variability and complexity. To address these challenges, we propose Bayesian Data Scheduler (BDS), an adaptive tuning-stage defense strategy with no need for attack simulation. BDS formulates harmful fine-tuning defense as a Bayesian inference problem, learning the posterior distribution of each data point's safety attribute, conditioned on the fine-tuning and alignment datasets. The fine-tuning process is then constrained by weighting data with their safety attributes sampled from the posterior, thus mitigating the influence of harmful data. By leveraging the post hoc nature of Bayesian inference, the posterior is conditioned on the fine-tuning dataset, enabling BDS to tailor its defense to the specific dataset, thereby achieving adaptive defense. Furthermore, we introduce a neural scheduler based on amortized Bayesian learning, enabling efficient transfer to new data without retraining. Comprehensive results across diverse attack and defense settings demonstrate the state-of-the-art performance of our approach. Code is available at https://github.com/Egg-Hu/Bayesian-Data-Scheduler.",
        "decision": "Accept (spotlight)",
        "review scores": [
            5,
            5,
            5,
            5,
            5
        ],
        "strengths": [],
        "weaknesses": []
    }
}